{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpP5wQwJEsFN"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hENTJbKcEsFS"
      },
      "source": [
        "\n",
        "Similarity Queries\n",
        "==================\n",
        "\n",
        "Demonstrates querying a corpus for similar documents.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlHDg3xQEsFU"
      },
      "source": [
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjpX7fi8EsFY"
      },
      "source": [
        "Creating the Corpus\n",
        "-------------------\n",
        "\n",
        "First, we need to create a corpus to work with.\n",
        "This step is the same as in the previous tutorial;\n",
        "if you completed it, feel free to skip to the next section.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch4Cm7OpEsFZ"
      },
      "source": [
        "from collections import defaultdict\n",
        "from gensim import corpora\n",
        "\n",
        "documents = [\n",
        "    \"Human machine interface for lab abc computer applications\",\n",
        "    \"A survey of user opinion of computer system response time\",\n",
        "    \"The EPS user interface management system\",\n",
        "    \"System and human system engineering testing of EPS\",\n",
        "    \"Relation of user perceived response time to error measurement\",\n",
        "    \"The generation of random binary unordered trees\",\n",
        "    \"The intersection graph of paths in trees\",\n",
        "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
        "    \"Graph minors A survey\",\n",
        "]\n",
        "\n",
        "# remove common words and tokenize\n",
        "stoplist = set('for a of the and to in'.split())\n",
        "texts = [\n",
        "    [word for word in document.lower().split() if word not in stoplist]\n",
        "    for document in documents\n",
        "]\n",
        "\n",
        "# remove words that appear only once\n",
        "frequency = defaultdict(int)\n",
        "for text in texts:\n",
        "    for token in text:\n",
        "        frequency[token] += 1\n",
        "\n",
        "texts = [\n",
        "    [token for token in text if frequency[token] > 1]\n",
        "    for text in texts\n",
        "]\n",
        "\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCktYd3QEsFb"
      },
      "source": [
        "Similarity interface\n",
        "--------------------\n",
        "\n",
        "In the previous tutorials on\n",
        "`sphx_glr_auto_examples_core_run_corpora_and_vector_spaces.py`\n",
        "and\n",
        "`sphx_glr_auto_examples_core_run_topics_and_transformations.py`,\n",
        "we covered what it means to create a corpus in the Vector Space Model and how\n",
        "to transform it between different vector spaces. A common reason for such a\n",
        "charade is that we want to determine **similarity between pairs of\n",
        "documents**, or the **similarity between a specific document and a set of\n",
        "other documents** (such as a user query vs. indexed documents).\n",
        "\n",
        "To show how this can be done in gensim, let us consider the same corpus as in the\n",
        "previous examples (which really originally comes from Deerwester et al.'s\n",
        "`\"Indexing by Latent Semantic Analysis\" <http://www.cs.bham.ac.uk/~pxt/IDA/lsa_ind.pdf>`_\n",
        "seminal 1990 article).\n",
        "To follow Deerwester's example, we first use this tiny corpus to define a 2-dimensional\n",
        "LSI space:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq1V7YaAEsFc"
      },
      "source": [
        "from gensim import models\n",
        "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMHZWgbuEsFe"
      },
      "source": [
        "For the purposes of this tutorial, there are only two things you need to know about LSI.\n",
        "First, it's just another transformation: it transforms vectors from one space to another.\n",
        "Second, the benefit of LSI is that enables identifying patterns and relationships between terms (in our case, words in a document) and topics.\n",
        "Our LSI space is two-dimensional (`num_topics = 2`) so there are two topics, but this is arbitrary.\n",
        "If you're interested, you can read more about LSI here: `Latent Semantic Indexing <https://en.wikipedia.org/wiki/Latent_semantic_indexing>`_:\n",
        "\n",
        "Now suppose a user typed in the query `\"Human computer interaction\"`. We would\n",
        "like to sort our nine corpus documents in decreasing order of relevance to this query.\n",
        "Unlike modern search engines, here we only concentrate on a single aspect of possible\n",
        "similarities---on apparent semantic relatedness of their texts (words). No hyperlinks,\n",
        "no random-walk static ranks, just a semantic extension over the boolean keyword match:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9MnA-iHEsFh"
      },
      "source": [
        "doc = \"Human computer interaction\"\n",
        "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
        "vec_lsi = lsi[vec_bow]  # convert the query to LSI space\n",
        "print(vec_lsi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmd-A2AAEsFm"
      },
      "source": [
        "In addition, we will be considering `cosine similarity <http://en.wikipedia.org/wiki/Cosine_similarity>`_\n",
        "to determine the similarity of two vectors. Cosine similarity is a standard measure\n",
        "in Vector Space Modeling, but wherever the vectors represent probability distributions,\n",
        "`different similarity measures <http://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Symmetrised_divergence>`_\n",
        "may be more appropriate.\n",
        "\n",
        "Initializing query structures\n",
        "++++++++++++++++++++++++++++++++\n",
        "\n",
        "To prepare for similarity queries, we need to enter all documents which we want\n",
        "to compare against subsequent queries. In our case, they are the same nine documents\n",
        "used for training LSI, converted to 2-D LSA space. But that's only incidental, we\n",
        "might also be indexing a different corpus altogether.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWC0VAWlEsFn"
      },
      "source": [
        "from gensim import similarities\n",
        "index = similarities.MatrixSimilarity(lsi[corpus])  # transform corpus to LSI space and index it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJXUbQVHEsFp"
      },
      "source": [
        "<div class=\"alert alert-danger\"><h4>Warning</h4><p>The class :class:`similarities.MatrixSimilarity` is only appropriate when the whole\n",
        "  set of vectors fits into memory. For example, a corpus of one million documents\n",
        "  would require 2GB of RAM in a 256-dimensional LSI space, when used with this class.\n",
        "\n",
        "  Without 2GB of free RAM, you would need to use the :class:`similarities.Similarity` class.\n",
        "  This class operates in fixed memory, by splitting the index across multiple files on disk, called shards.\n",
        "  It uses :class:`similarities.MatrixSimilarity` and :class:`similarities.SparseMatrixSimilarity` internally,\n",
        "  so it is still fast, although slightly more complex.</p></div>\n",
        "\n",
        "Index persistency is handled via the standard :func:`save` and :func:`load` functions:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35zO8faKEsFq"
      },
      "source": [
        "index.save('/tmp/deerwester.index')\n",
        "index = similarities.MatrixSimilarity.load('/tmp/deerwester.index')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_0sw2dkEsFs"
      },
      "source": [
        "This is true for all similarity indexing classes (:class:`similarities.Similarity`,\n",
        ":class:`similarities.MatrixSimilarity` and :class:`similarities.SparseMatrixSimilarity`).\n",
        "Also in the following, `index` can be an object of any of these. When in doubt,\n",
        "use :class:`similarities.Similarity`, as it is the most scalable version, and it also\n",
        "supports adding more documents to the index later.\n",
        "\n",
        "Performing queries\n",
        "++++++++++++++++++\n",
        "\n",
        "To obtain similarities of our query document against the nine indexed documents:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke6s_cn_EsFt"
      },
      "source": [
        "sims = index[vec_lsi]  # perform a similarity query against the corpus\n",
        "print(list(enumerate(sims)))  # print (document_number, document_similarity) 2-tuples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKRK1YznEsFw"
      },
      "source": [
        "Cosine measure returns similarities in the range `<-1, 1>` (the greater, the more similar),\n",
        "so that the first document has a score of 0.99809301 etc.\n",
        "\n",
        "With some standard Python magic we sort these similarities into descending\n",
        "order, and obtain the final answer to the query `\"Human computer interaction\"`:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2r9AwLREsFy"
      },
      "source": [
        "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
        "for i, s in enumerate(sims):\n",
        "    print(s, documents[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkXTagWSEsF1"
      },
      "source": [
        "The thing to note here is that documents no. 2 (``\"The EPS user interface management system\"``)\n",
        "and 4 (``\"Relation of user perceived response time to error measurement\"``) would never be returned by\n",
        "a standard boolean fulltext search, because they do not share any common words with ``\"Human\n",
        "computer interaction\"``. However, after applying LSI, we can observe that both of\n",
        "them received quite high similarity scores (no. 2 is actually the most similar!),\n",
        "which corresponds better to our intuition of\n",
        "them sharing a \"computer-human\" related topic with the query. In fact, this semantic\n",
        "generalization is the reason why we apply transformations and do topic modelling\n",
        "in the first place.\n",
        "\n",
        "Where next?\n",
        "------------\n",
        "\n",
        "Congratulations, you have finished the tutorials -- now you know how gensim works :-)\n",
        "To delve into more details, you can browse through the `apiref`,\n",
        "see the `wiki` or perhaps check out `distributed` in `gensim`.\n",
        "\n",
        "Gensim is a fairly mature package that has been used successfully by many individuals and companies, both for rapid prototyping and in production.\n",
        "That doesn't mean it's perfect though:\n",
        "\n",
        "* there are parts that could be implemented more efficiently (in C, for example), or make better use of parallelism (multiple machines cores)\n",
        "* new algorithms are published all the time; help gensim keep up by `discussing them <http://groups.google.com/group/gensim>`_ and `contributing code <https://github.com/piskvorky/gensim/wiki/Developer-page>`_\n",
        "* your **feedback is most welcome** and appreciated (and it's not just the code!):\n",
        "  `bug reports <https://github.com/piskvorky/gensim/issues>`_ or\n",
        "  `user stories and general questions <http://groups.google.com/group/gensim/topics>`_.\n",
        "\n",
        "Gensim has no ambition to become an all-encompassing framework, across all NLP (or even Machine Learning) subfields.\n",
        "Its mission is to help NLP practitioners try out popular topic modelling algorithms\n",
        "on large datasets easily, and to facilitate prototyping of new algorithms for researchers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1-pkvdFEsF2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "img = mpimg.imread('run_similarity_queries.png')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrZODroClfkG"
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "from urllib.error import HTTPError\n",
        "import urllib.request\n",
        "import threading\n",
        "import datetime\n",
        "import random\n",
        "import time\n",
        "import csv\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILYP5Iiyll_9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1c7522f-4f5a-4e91-b9fb-bff6b3a40739"
      },
      "source": [
        "date = datetime.datetime.now()\n",
        "currDate = '{}/{}/{}'.format(date.day,date.month,date.year)\n",
        "random.seed(datetime.datetime.now())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-29611f912228>:3: DeprecationWarning: Seeding based on hashing is deprecated\n",
            "since Python 3.9 and will be removed in a subsequent version. The only \n",
            "supported seed types are: None, int, float, str, bytes, and bytearray.\n",
            "  random.seed(datetime.datetime.now())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIFSppxVmCgZ"
      },
      "source": [
        "# Directories for the BBC news webpages I'm interested in\n",
        "BBCArticleURLs = ('News',\n",
        "'Modi/Indai','Modi/BJP','BJP/Congress','Modi/Rahul Gandhi','BJP/Modi',\n",
        "'Congress/Rahul Gandhi')\n",
        "\n",
        "# Directories for the CNN news webpages I'm interested in\n",
        "CNNArticleURLs = ('Modi',\n",
        "'Modi/Indai','Modi/BJP','BJP/Congress','Modi/Rahul Gandhi','BJP/Modi',\n",
        "'Congress/Rahul Gandhi')\n",
        "\n",
        "# Directories for the CNN news webpages I'm interested in\n",
        "RTArticleURLs = ('Modi',\n",
        "'Modi/Indai','Modi/BJP','BJP/Congress','Modi/Rahul Gandhi','BJP/Modi',\n",
        "'Congress/Rahul Gandhi')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAI1KNc_muQY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9e8b915-6ba0-4f77-e874-d4316e9ee395"
      },
      "source": [
        "# Directories for the BBC news webpages I'm interested in\n",
        "BBCArticleURLs = ('News',\n",
        "'Modi/Indai','Modi/BJP','BJP/Congress','Modi/Rahul Gandhi','BJP/Modi',\n",
        "'Congress/Rahul Gandhi')\n",
        "\n",
        "# Directories for the CNN news webpages I'm interested in\n",
        "CNNArticleURLs = ('Modi',\n",
        "'Modi/Indai','Modi/BJP','BJP/Congress','Modi/Rahul Gandhi','BJP/Modi',\n",
        "'Congress/Rahul Gandhi')\n",
        "\n",
        "# Directories for the CNN news webpages I'm interested in\n",
        "RTArticleURLs = ('Modi',\n",
        "'Modi/Indai','Modi/BJP','BJP/Congress','Modi/Rahul Gandhi','BJP/Modi',\n",
        "'Congress/Rahul Gandhi')\n",
        "\n",
        "\n",
        "def getArticles(dir, website):\n",
        "    try:\n",
        "        if website == 'BBC':\n",
        "            tree = ET.parse(source=urllib.request.urlopen('http://feeds.bbci.co.uk/news/'+dir+'/rss.xml'))\n",
        "        elif website == 'CNN':\n",
        "            tree = ET.parse(source=urllib.request.urlopen('http://rss.cnn.com/rss/'+dir+'.rss'))\n",
        "        elif website == 'RT':\n",
        "            tree = ET.parse(source=urllib.request.urlopen('https://www.rt.com/rss/'+dir))\n",
        "        else:\n",
        "            tree = ET.parse(source=urllib.request.urlopen('https://www.theguardian.com/sitemaps/news.xml'))\n",
        "    except HTTPError as err:\n",
        "        print(err)\n",
        "        return None\n",
        "    except ET.ParseError as err:\n",
        "        return None\n",
        "    else:\n",
        "        # Gets the xml tree as an object which\n",
        "        # is then used to extract the articles\n",
        "        root = tree.getroot()\n",
        "        if website != 'guardian':\n",
        "            allArticles = list()\n",
        "            # TODO: fix issue with filtering bad titles\n",
        "            # e.g 'RT UK News' or 'CNN.com - RSS' etc\n",
        "            for elem in root.iter('title'):\n",
        "                allArticles.append(elem.text)\n",
        "            return allArticles\n",
        "        else:\n",
        "            i = 0\n",
        "            if dir == 'titles':\n",
        "                allTitles = list()\n",
        "                for elem in root.iter('{http://www.google.com/schemas/sitemap-news/0.9}title'):\n",
        "                    allTitles.append(elem.text.strip())\n",
        "                    i += 1\n",
        "                print('{} article titles scraped'.format(i))\n",
        "                return allTitles\n",
        "\n",
        "            else:\n",
        "                # Returns a list where each element is a list containing\n",
        "                # the keywords for an article title\n",
        "                allKeywords = list()\n",
        "                tempKeywords = list()\n",
        "                keywordString = ''\n",
        "\n",
        "                for elem in root.iter('{http://www.google.com/schemas/sitemap-news/0.9}keywords'):\n",
        "                    keywordString = elem.text\n",
        "                    try:\n",
        "                        tempKeywords = keywordString.split(',')\n",
        "                    except AttributeError as err:\n",
        "                        print('Guardian article {} had no keywords'.format(i))\n",
        "                        tempKeywords = ['no keywords']\n",
        "                    allKeywords.append(tempKeywords)\n",
        "                    i += 1\n",
        "                print('{} article keyword lists scraped'.format(i))\n",
        "                return allKeywords\n",
        "\n",
        "\n",
        "def writeCSV(articleList, dir, invalid, website):\n",
        "    if invalid:\n",
        "        with open('errorLog.csv', 'a', encoding=\"utf-8\") as file:\n",
        "            fields = ['date', 'website', 'dir', 'articleTitle']\n",
        "            writeObj = csv.DictWriter(file, fieldnames=fields,lineterminator='\\n')\n",
        "\n",
        "            for article in articleList:\n",
        "                writeObj.writerow({'date':'{}'.format(currDate),'website':'{}'.format(website), 'dir':'{}'.format(dir),'articleTitle':'{}'.format(article)})\n",
        "    else:\n",
        "        with open('{}infoXML.csv'.format(website), 'a', encoding=\"utf-8\") as file:\n",
        "            fields = ['date', 'dir', 'articleTitle']\n",
        "            writeObj = csv.DictWriter(file, fieldnames=fields,lineterminator='\\n')\n",
        "\n",
        "            for article in articleList:\n",
        "                writeObj.writerow({'date':'{}'.format(currDate),'dir':'{}'.format(dir),'articleTitle':'{}'.format(article)})\n",
        "\n",
        "\n",
        "def writeGuardianCSV(allTitles, allKeywords, date, invalid):\n",
        "    if invalid:\n",
        "        with open('errorLog.csv', 'a', encoding='utf-8') as file:\n",
        "            i = 0\n",
        "            fields = ['date', 'website', 'keywordsArr', 'articleTitle']\n",
        "            writeObj = csv.DictWriter(file, fieldnames=fields, delimiter=',',lineterminator='\\n')\n",
        "\n",
        "            for title, keywords in zip(allTitles, allKeywords):\n",
        "                writeObj.writerow({'date':'{}'.format(currDate), 'website':'{}'.format(website), 'keywordsArr':'{}'.format(keywords),'articleTitle':'{}'.format(title)})\n",
        "                i += 1\n",
        "    else:\n",
        "        with open('guardianInfoXML.csv', 'a', encoding='utf-8') as file:\n",
        "            i = 0\n",
        "            fields = ['date','keywordsArr', 'articleTitle']\n",
        "            writeObj = csv.DictWriter(file, fieldnames=fields, delimiter=',',lineterminator='\\n')\n",
        "\n",
        "            for title, keywords in zip(allTitles, allKeywords):\n",
        "                writeObj.writerow({'date':'{}'.format(currDate),'keywordsArr':'{}'.format(keywords),'articleTitle':'{}'.format(title)})\n",
        "                i += 1\n",
        "\n",
        "\n",
        "def scrape(dir, website):\n",
        "    if website != 'guardian':\n",
        "        allArticles = getArticles(dir, website)\n",
        "        if allArticles != None:\n",
        "            writeCSV(allArticles, dir, 0, website)\n",
        "            if website == 'BBC' or 'guardian' or 'RT':\n",
        "                print('Downloaded articles from section: {} - {}'.format(website, dir))\n",
        "            elif website == 'CNN':\n",
        "                print('Downloaded articles from section: {} - {}'.format(website, dir[8:]))\n",
        "        else:\n",
        "            badscrapeMsg = 'Error could not scrape from section: {}'.format(dir)\n",
        "            badscrape = list()\n",
        "            badscrape.append(badscrapeMsg)\n",
        "            writeCSV(badscrape, dir, 1, website)\n",
        "            print('############ Failed to download articles from section: {} ############ '.format(dir))\n",
        "    # If scraping from the guardian, slightly different format\n",
        "    # due to the keywords list used\n",
        "    if dir == 'titles':\n",
        "        titlesList = getArticles('titles', 'guardian')\n",
        "        return titlesList\n",
        "    if dir == 'keywords':\n",
        "        keywordsList = getArticles('keywords', 'guardian')\n",
        "        return keywordsList\n",
        "\n",
        "\n",
        "def BBCControl():\n",
        "    for target in BBCArticleURLs:\n",
        "        scrape(target, 'BBC')\n",
        "        time.sleep(random.random())\n",
        "\n",
        "\n",
        "def CNNControl():\n",
        "    for target in CNNArticleURLs:\n",
        "        scrape(target, 'CNN')\n",
        "        time.sleep(random.random())\n",
        "\n",
        "\n",
        "def RTControl():\n",
        "    for target in RTArticleURLs:\n",
        "        scrape(target, 'RT')\n",
        "        time.sleep(random.random())\n",
        "\n",
        "\n",
        "def guardianControl():\n",
        "    titlesList = scrape('titles', 'guardian')\n",
        "    keywordsList = scrape('keywords', 'guardian')\n",
        "\n",
        "    if titlesList and keywordsList != None:\n",
        "        writeGuardianCSV(titlesList, keywordsList, currDate, 0)\n",
        "    else:\n",
        "        writeGuardianCSV(titlesList, keywordsList, currDate, 1)\n",
        "\n",
        "def main():\n",
        "    threading.Thread(target=BBCControl).start()\n",
        "    threading.Thread(target=CNNControl).start()\n",
        "    threading.Thread(target=guardianControl).start()\n",
        "    threading.Thread(target=RTControl).start()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############ Failed to download articles from section: News ############ \n",
            "HTTP Error 404: Not Found\n",
            "############ Failed to download articles from section: Modi ############ \n",
            "539 article titles scraped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "allArticles"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "LGc-mcravOP7",
        "outputId": "2345a6d2-0224-4c69-84b5-2dbebb1155cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-c2cbbd7f0816>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mallArticles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'allArticles' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4FaAvltqxOt"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aJyh4qmq7i-"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bqJlIWAMMX9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "92498e43-282c-4a6b-c932-671bcbbc2e3e"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import random\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "class FactOrFeelModel(object):\n",
        "\tlog_model = LogisticRegression()\n",
        "\tvectorizer = CountVectorizer()\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\t# load the model from disk\n",
        "\t\tfilename = 'finalized_model.sav'\n",
        "\t\tif (sys.version_info > (3, 0)): # if python3\n",
        "\t\t\twith open(filename,'rb') as f:\n",
        "\t\t\t\tself.log_model = pickle.load(f, encoding='latin1')\n",
        "\t\telse:\n",
        "\t\t\tself.log_model = pickle.load(open(filename, 'rb'))\n",
        "\n",
        "\n",
        "\t\t#load the vectorizer from the disk\n",
        "\t\tfilename2 = 'vectorizer.sav'\n",
        "\t\tif (sys.version_info > (3, 0)):\t# if python 3\n",
        "\t\t\twith open(filename2,'rb') as f:\n",
        "\t\t\t\tself.vectorizer = pickle.load(f, encoding='latin1')\n",
        "\t\telse:\n",
        "\t\t\tself.vectorizer = pickle.load(open(filename2, 'rb'))\n",
        "\n",
        "\tdef example(self):\n",
        "\t\ttext1 = \"You should be proud of yourself\"\n",
        "\t\ttext2 = \"The lab coat is white\"\n",
        "\t\tdata = [text1,text2]\n",
        "\t\tprint_results(data)\n",
        "\n",
        "\t# data can be of the form string or [string]\n",
        "\t# returns ['fact'] or ['feel']\n",
        "\tdef make_prediction(self,data):\n",
        "\t\tprediction = ''\n",
        "\t\tif type(data) == str:\n",
        "\t\t\tdata = [data]\n",
        "\t\t\treturn self.log_model.predict(self.vectorizer.transform(data).toarray())\n",
        "\t\telif type(data) == list:\n",
        "\t\t\treturn self.log_model.predict(self.vectorizer.transform(data).toarray())\n",
        "\t\telse:\n",
        "\t\t\traise ValueError(\"data must be either list of strings or a string but is of type \" + str(type(data)))\n",
        "\n",
        "\t# text is a string\n",
        "\t# num_sentences_per_eval is the number of sentences for each prediction (NOT CURRENT IN USE)\n",
        "\t# returns the percent of feel and fact\n",
        "\tdef evaluateText(self,text):\n",
        "\t\tfactCounter = 0\n",
        "\t\tfeelCounter = 0\n",
        "\n",
        "\t\tmodel = FactOrFeelModel()\n",
        "\t\tsplitText = text.split('.')\n",
        "\t\tsplitText.pop()\n",
        "\t\tsplitText = [x+y for x,y in zip(splitText[0::2], splitText[1::2])] #each prediciton is two sentences\n",
        "\n",
        "\t\tpreds = model.make_prediction(splitText)\n",
        "\n",
        "\t\tfor pred in preds:\n",
        "\t\t\tif type(pred) != str:\n",
        "\t\t\t\tpred = pred.decode(\"utf-8\")\n",
        "\t\t\tif pred == 'fact':\n",
        "\t\t\t\tfactCounter+=1\n",
        "\t\t\telse:\n",
        "\t\t\t\tfeelCounter+=1\n",
        "\n",
        "\t\tpercentFacts = int(float(factCounter)/float(factCounter+feelCounter) * 100)\n",
        "\t\tpercentFeels = int(float(feelCounter)/float(feelCounter+factCounter) * 100)\n",
        "\n",
        "\t\treturn [percentFacts,percentFeels]\n",
        "\n",
        "\tdef printEvaluations(self, percentages):\n",
        "\t\tprint(\"facts: \" + str(percentages[0]) + \"% | feels: \" + str(percentages[1]) + \"% | Predictions accuracy: 73%\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\tmodel = FactOrFeelModel()\n",
        "\tpath = '/content/trump.txt'\n",
        "\twith open(path, 'r') as content_file:\n",
        "\t\tcontent = content_file.read()\n",
        "\t\tpercentages = model.evaluateText(content)\n",
        "\t\tmodel.printEvaluations(percentages)\n",
        "\n",
        "\t# while(True):\n",
        "\t# \tdata = raw_input(\"Enter a sentance. (type 'q' to quit)\\n\")\n",
        "\t# \tif data == \"q\":\n",
        "\t# \t\tbreak\n",
        "\t# \tprint(model.make_prediction(data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b91019709059>\u001b[0m in \u001b[0;36m<cell line: 81>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFactOrFeelModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/trump.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontent_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-b91019709059>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'finalized_model.sav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# if python3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'finalized_model.sav'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu_NQR4TrbPr"
      },
      "source": [
        "pip install spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYa6dU2hrdqQ"
      },
      "source": [
        "\n",
        "article = '''\n",
        "Asian shares skidded on Tuesday after a rout in tech stocks put Wall Street to the sword, while a\n",
        "sharp drop in oil prices and political risks in Europe pushed the dollar to 16-month highs as investors dumped\n",
        "riskier assets. MSCI’s broadest index of Asia-Pacific shares outside Japan dropped 1.7 percent to a 1-1/2\n",
        "week trough, with Australian shares sinking 1.6 percent. Japan’s Nikkei dived 3.1 percent led by losses in\n",
        "electric machinery makers and suppliers of Apple’s iphone parts. Sterling fell to $1.286 after three straight\n",
        "sessions of losses took it to the lowest since Nov.1 as there were still considerable unresolved issues with the\n",
        "European Union over Brexit, British Prime Minister Theresa May said on Monday.'''\n",
        "\n",
        "import spacy\n",
        "\n",
        "spacy_nlp = spacy.load('en')\n",
        "document = spacy_nlp(article)\n",
        "\n",
        "print('Original Sentence: %s' % (article))\n",
        "\n",
        "for element in document.ents:\n",
        "    print('Type: %s, Value: %s' % (element.label_, element))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHypdAXkvd3h"
      },
      "source": [
        "class SkillsExtractorNN:\n",
        "\n",
        "    def __init__(self, word_features_dim, dense_features_dim):\n",
        "\n",
        "        lstm_input_phrase = keras.layers.Input(shape=(None, word_features_dim))\n",
        "        lstm_input_cont = keras.layers.Input(shape=(None, word_features_dim))\n",
        "        dense_input = keras.layers.Input(shape=(dense_features_dim,))\n",
        "\n",
        "        lstm_emb_phrase = keras.layers.LSTM(256)(lstm_input_phrase)\n",
        "        lstm_emb_phrase = keras.layers.Dense(128, activation='relu')(lstm_emb_phrase)\n",
        "\n",
        "        lstm_emb_cont = keras.layers.LSTM(256)(lstm_input_cont)\n",
        "        lstm_emb_cont = keras.layers.Dense(128, activation='relu')(lstm_emb_cont)\n",
        "\n",
        "        dense_emb = keras.layers.Dense(512, activation='relu')(dense_input)\n",
        "        dense_emb = keras.layers.Dense(256, activation='relu')(dense_emb)\n",
        "\n",
        "        x = keras.layers.concatenate([lstm_emb_phrase, lstm_emb_cont, dense_emb])\n",
        "        x = keras.layers.Dense(128, activation='relu')(x)\n",
        "        x = keras.layers.Dense(64, activation='relu')(x)\n",
        "        x = keras.layers.Dense(32, activation='relu')(x)\n",
        "\n",
        "        main_output = keras.layers.Dense(2, activation='softplus')(x)\n",
        "\n",
        "        self.model = keras.models.Model(inputs=[lstm_input_phrase, lstm_input_cont, dense_input],\n",
        "                                        outputs=main_output)\n",
        "\n",
        "        optimizer = keras.optimizers.Adam(lr=0.0001)\n",
        "\n",
        "        self.model.compile(optimizer=optimizer, loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDFcsRI6v5n1"
      },
      "source": [
        "SkillsExtractorNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOlar6zNw6fa"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0Us3ZJ1vfA1"
      },
      "source": [
        "def fit(self, x_lstm_phrase, x_lstm_context, x_dense, y,\n",
        "            val_split=0.25, patience=5, max_epochs=1000, batch_size=32):\n",
        "\n",
        "        x_lstm_phrase_seq = keras.preprocessing.sequence.pad_sequences(x_lstm_phrase)\n",
        "        x_lstm_context_seq = keras.preprocessing.sequence.pad_sequences(x_lstm_context)\n",
        "\n",
        "        y_onehot = onehot_transform(y)\n",
        "\n",
        "        self.model.fit([x_lstm_phrase_seq, x_lstm_context_seq, x_dense],\n",
        "                       y_onehot,\n",
        "                       batch_size=batch_size,\n",
        "                       pochs=max_epochs,\n",
        "                       validation_split=val_split,\n",
        "                       callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)])\n",
        "\n",
        "def predict(self, x_lstm_phrase, x_lstm_context, x_dense):\n",
        "\n",
        "  x_lstm_phrase_seq = keras.preprocessing.sequence.pad_sequences(x_lstm_phrase)\n",
        "  x_lstm_context_seq = keras.preprocessing.sequence.pad_sequences(x_lstm_context)\n",
        "\n",
        "  y = self.model.predict([x_lstm_phrase_seq, x_lstm_context_seq, x_dense])\n",
        "\n",
        "  return y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZADkEUtv1JX"
      },
      "source": [
        "def onehot_transform(y):\n",
        "\n",
        "    onehot_y = []\n",
        "\n",
        "    for numb in y:\n",
        "        onehot_arr = np.zeros(2)\n",
        "        onehot_arr[numb] = 1\n",
        "        onehot_y.append(np.array(onehot_arr))\n",
        "\n",
        "    return np.array(onehot_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R2dWQRxw7WD"
      },
      "source": [
        "from urllib.request import urlopen\n",
        "url = urlopen(\"http://venturebeat.com/2014/07/04/facebooks-little-social-experiment-got-you-bummed-out-get-over-it/\")\n",
        "#contents = url.read()\n",
        "html = url.read()\n",
        "html[:500]\n",
        "\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX1Ds_dQx0BT"
      },
      "source": [
        "print(soup.get_text())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QFAnBcQxAPB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "a918c3ba-046e-4873-bd85-50356181ed65"
      },
      "source": [
        "from readability.readability import Document\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "readable_article = Document(html).summary()\n",
        "readable_title = Document(html).title()\n",
        "soup = BeautifulSoup(readable_article)\n",
        "print('*** TITLE *** \\n\\\"' + readable_title + '\\\"\\n')\n",
        "print('*** CONTENT *** \\n\\\"' + soup.text[:500] + '[...]\\\"')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-51d652e19b27>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mreadability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadability\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreadable_article\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mreadable_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'readability'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5nYM_n91JRh"
      },
      "source": [
        "import nltk\n",
        "tokens = [word for sent in nltk.sent_tokenize(soup.text) for word in nltk.word_tokenize(sent)]\n",
        "\n",
        "for token in sorted(set(tokens))[:30]:\n",
        "    print(token + ' [' + str(tokens.count(token)) + ']')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkxO2Qci2fL9"
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "stemmed_tokens = [stemmer.stem(t) for t in tokens]\n",
        "\n",
        "for token in sorted(set(stemmed_tokens))[50:75]:\n",
        "    print(token+ ' [' + str(stemmed_tokens.count(token)) + ']')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llzzCwYr2zzh"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qar381EB5geq"
      },
      "source": [
        "\n",
        "import requests\n",
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m5nD0gL5iyQ"
      },
      "source": [
        "page = requests.get('https://qz.com/africa/latest')\n",
        "soup = BeautifulSoup(page.content, 'html.parser')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z33emKnd5n8h"
      },
      "source": [
        "weblinks = soup.find_all('article')\n",
        "pagelinks = []\n",
        "for link in weblinks[5:]:\n",
        "      url = link.contents[0].find_all('a')[0]\n",
        "      pagelinks.append('http://qz.com'+url.get('href'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQwaU1dD-UfE"
      },
      "source": [
        "from newspaper import Article"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Orn-TZ1y-W3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35b92290-6090-4c93-cded-af97f6b22c9e"
      },
      "source": [
        "pip install newspaper3k"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting newspaper3k\n",
            "  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/211.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/211.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.11.2)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (8.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (6.0.1)\n",
            "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.9.3)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (3.8.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.27.1)\n",
            "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
            "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tldextract>=2.0.1 (from newspaper3k)\n",
            "  Downloading tldextract-3.4.4-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting feedfinder2>=0.0.4 (from newspaper3k)\n",
            "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
            "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.8.2)\n",
            "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
            "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
            "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (1.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (4.65.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (3.4)\n",
            "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.12.2)\n",
            "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13541 sha256=f203b921e3a2a8cdb52bd64129b0cb85bd5974b74f8d1497af8ad0e08b9b3f46\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/d6/6c/384f58df48c00b9a31d638005143b5b3ac62c3d25fb1447f23\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3341 sha256=c895311f872c81d1c708b47b8bef824dd9920e6beacdb2eab0f08aed94d6bac2\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/02/e7/a1ff1760e12bdbaab0ac824fae5c1bc933e41c4ccd6a8f8edb\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398382 sha256=12007b0ca16e010d06f423bb0441e60954361e10404436db17c1677a1c901a18\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/c4/0c/12a9a314ecac499456c4c3b2fcc2f635a3b45a39dfbd240299\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=6ac13fc2a4ba7d5bd8d39c746fa9753efc0db13e88c910856e23baf40d2e6da5\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
            "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, feedparser, cssselect, requests-file, feedfinder2, tldextract, newspaper3k\n",
            "Successfully installed cssselect-1.2.0 feedfinder2-0.0.4 feedparser-6.0.10 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-3.4.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwAfHNIA-mrb"
      },
      "source": [
        "url1 = 'https://www.vox.com/platform/amp/2019/11/26/20983690/trump-impeachment-hearings-women-poll-2020-democrats'\n",
        "article1 = Article(url1)\n",
        "\n",
        "url2 = 'https://amp.cnn.com/cnn/2019/11/26/politics/trump-cnn-impeachment-poll/index.html'\n",
        "article2 = Article(url2)\n",
        "\n",
        "url3 = 'https://amp.usatoday.com/amp/4305749002'\n",
        "article3 = Article(url3)\n",
        "\n",
        "url4 = 'https://mobile.reuters.com/article/amp/idUSKBN1Y02MO'\n",
        "article4 = Article(url4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQP0Bk8e-tK3"
      },
      "source": [
        "article1.download()\n",
        "\n",
        "article2.download()\n",
        "\n",
        "article3.download()\n",
        "\n",
        "article4.download()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2JokxeX-xtc",
        "outputId": "cd8d63e7-520b-4cf9-c2d1-0c4f39259fe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "article2.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<!doctype html>\\n<html amp lang=\"en\">\\n  <head>\\n    <meta charset=\"utf-8\">\\n    <title>The new Donald Trump impeachment poll is not good news for the President - CNNPolitics</title>\\n    <link rel=\"shortcut icon\" href=\"/static/cnn-favicon.png\">\\n    <meta property=\"og:pubdate\" content=\"2019-11-26T21:18:54Z\">\\n    <meta property=\"og:url\" content=\"https://www.cnn.com/2019/11/26/politics/trump-cnn-impeachment-poll/index.html\" >\\n    <meta property=\"og:title\" content=\"No, the new CNN poll is not good news for Donald Trump on impeachment\">\\n    <meta property=\"og:description\" content=\"A new CNN poll shows that half the country believes that President Donald Trump should be not only impeached by the House, but also removed from office by the Senate.\" >\\n    <meta property=\"og:site_name\" content=\"CNN\" >\\n    <meta property=\"og:type\" content=\"article\" >\\n    <meta property=\"og:image\" content=\"https://cdn.cnn.com/cnnnext/dam/assets/191002164147-11-trump-impeachment-inquiry-super-tease.jpg\">\\n    <meta name=\"twitter:card\" content=\"summary_large_image\" >\\n    <meta name=\"viewport\" content=\"width=device-width,minimum-scale=1,initial-scale=1\">\\n        <meta name=\"apple-itunes-app\" content=\"app-id=331786748\">\\n    <link rel=\"canonical\" href=\"https://www.cnn.com/2019/11/26/politics/trump-cnn-impeachment-poll/index.html\" />\\n    \\n    <script type=\"application/ld+json\">\\n      {\\n        \"@context\": \"http://schema.org\",\\n        \"@type\": \"NewsArticle\",\\n        \"mainEntityOfPage\": \"https://www.cnn.com/2019/11/26/politics/trump-cnn-impeachment-poll/index.html\",\\n        \"headline\": \"No, the new CNN poll is not good news for Donald Trump on impeachment\",\\n        \"description\": \"A new CNN poll shows that half the country believes that President Donald Trump should be not only impeached by the House, but also removed from office by the Senate.\",\\n        \"datePublished\": \"2019-11-26T21:18:54Z\",\\n        \"dateModified\": \"2019-11-26T21:18:54Z\",\\n        \"author\": {\\n            \"@type\": \"Person\",\\n            \"name\": \"Analysis by Chris Cillizza, CNN Editor-at-large \"\\n        },\\n        \"publisher\": {\\n            \"@type\": \"Organization\",\\n            \"name\": \"CNN\",\\n            \"logo\": {\\n                \"@type\": \"ImageObject\",\\n                \"url\": \"https://amp.cnn.com/static/cnn-publisher-image.png\",\\n                \"width\": 103,\\n                \"height\": 60\\n            }\\n        }\\n        ,\"image\": {\\n            \"@type\": \"ImageObject\",\\n            \"url\": \"https://dynaimage.cdn.cnn.com/cnn/c_fill,g_auto,w_1200,h_675,ar_16:9/https%3A%2F%2Fcdn.cnn.com%2Fcnnnext%2Fdam%2Fassets%2F191002164147-11-trump-impeachment-inquiry.jpg\",\\n            \"width\": 1200,\\n            \"height\": 675\\n        }\\n      }\\n    </script>\\n    \\n    <script async src=\"https://cdn.ampproject.org/v0.js\"></script>\\n    <script async custom-element=\"amp-sidebar\" src=\"https://cdn.ampproject.org/v0/amp-sidebar-0.1.js\"></script>\\n    <script async custom-element=\"amp-iframe\" src=\"https://cdn.ampproject.org/v0/amp-iframe-0.1.js\"></script>\\n        <script async custom-element=\"amp-app-banner\" src=\"https://cdn.ampproject.org/v0/amp-app-banner-0.1.js\"></script>\\n        <link rel=\"manifest\" href=\"https://cdn.cnn.com/cnn/ampfiles/ampbanner/cnn-app-banner-manifest.json\">\\n    \\n    \\n    \\n        <script async custom-element=\"amp-analytics\" src=\"https://cdn.ampproject.org/v0/amp-analytics-0.1.js\"></script>\\n    \\n    <script async custom-element=\"amp-social-share\" src=\"https://cdn.ampproject.org/v0/amp-social-share-0.1.js\"></script>\\n    \\n    <script async custom-element=\"amp-ad\" src=\"https://cdn.ampproject.org/v0/amp-ad-0.1.js\"></script>\\n    \\n    <style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>\\n    <style amp-custom>\\n        @font-face { font-family: \"CNN\"; src:\\n        url(\"https://www.i.cdn.cnn.com/.a/fonts/cnn/3.9.0/cnnsans-light.woff2\")\\n        format(\"woff2\"),\\n        url(\"https://www.i.cdn.cnn.com/.a/fonts/cnn/3.9.0/cnnsans-light.woff\")\\n        format(\"woff\"); font-weight: 300; font-style: normal; } @font-face {\\n        font-family: \"CNN\"; src:\\n        url(\"https://www.i.cdn.cnn.com/.a/fonts/cnn/3.9.0/cnnsans-regular.woff2\")\\n        format(\"woff2\"),\\n        url(\"https://www.i.cdn.cnn.com/.a/fonts/cnn/3.9.0/cnnsans-regular.woff\")\\n        format(\"woff\"); font-weight: 400; font-style: normal; } @font-face {\\n        font-family: \"CNN\"; src:\\n        url(\"https://www.i.cdn.cnn.com/.a/fonts/cnn/3.9.0/cnnsans-medium.woff2\")\\n        format(\"woff2\"),\\n        url(\"https://www.i.cdn.cnn.com/.a/fonts/cnn/3.9.0/cnnsans-medium.woff\")\\n        format(\"woff\"); font-weight: 500; font-style: normal; } @font-face {\\n        font-family: \"CNN\"; src:\\n        url(\"https://www.i.cdn.cnn.com/.a/fonts/cnn/3.9.0/cnnsans-bold.woff2\")\\n        format(\"woff2\"),\\n        url(\"https://www.i.cdn.cnn.com/.a/fonts/cnn/3.9.0/cnnsans-bold.woff\")\\n        format(\"woff\"); font-weight: 700; font-style: normal; } @font-face {\\n        font-family: \"CNN\"; src:\\n        url(\"https://www.i.cdn.cnn.com/.a/fonts/cnn/3.9.0/cnnsans-lightit.woff2\")\\n        format(\"woff2\"),\\n        url(\"https://www.i.cdn.cnn.com/.a/fonts/cnn/3.9.0/cnnsans-lightit.woff\")\\n        format(\"woff\"); font-weight: 300; font-style: italic; } @font-face {\\n        font-family: \"CNN\"; src:\\n        url(\"https://www.i.cdn.cnn.com/.a/fonts/cnn/3.9.0/cnnsans-italic.woff2\")\\n        format(\"woff2\"), url(\"https://www.i.cdn.cnn.com/cnnsans-italic.woff\")\\n        format(\"woff\"); font-weight: 400; font-style: italic; } @font-face {\\n        font-family: \"CNN\"; src:\\n        url(\"https://www.i.cdn.cnn.com/.a/fonts/cnn/3.9.0/cnnsans-boldit.woff2\")\\n        format(\"woff2\"),\\n        url(\"https://www.i.cdn.cnn.com/.a/fonts/cnn/3.9.0/cnnsans-boldit.woff\")\\n        format(\"woff\"); font-weight: 700; font-style: italic; } @font-face {\\n        font-family: \"CNN Business\"; src:\\n        url(\"https://www.i.cdn.cnn.com/.a/fonts/cnn/3.9.0/cnnbiz-heavy.woff2\")\\n        format(\"woff2\"),\\n        url(\"https://www.i.cdn.cnn.com/.a/fonts/cnn/3.9.0/cnnbiz-heavy.woff\")\\n        format(\"woff\"); font-weight: 800; font-style: normal; }\\n        :root { --cnn_red: #cc0000; --gray_4: #d9d9d9; --gray_5: #737373; --gray_6: #404040; --gray_7: #262626; --gray_8: #0c0c0c; --line_height_sm: 1.625; --line_height_lg: 1.25; --weight_light: 300; --weight_bold: 700; --space_2xs: 4px; --space_xs: 8px; --space_s: 12px; --space_m: 16px; --space_l: 24px; --space_xl: 32px; --bp_tablet_start: 700px; --bp_tablet_end: 1023px; --bp_desktop_regular_start: 1024px; } /* Typography */ h1, h2, h3, h4, h5, h6 { line-height: var(--line_height_lg); margin: 0 0 var(--space_l); } h1 { font-size: 26px; } h2 { font-size: 24px; } h3 { font-size: 22px; } h4 { font-size: 20px; } h5 { font-size: 18px; } h6 { font-size: 16px; } @media (min-width: var(--bp_tablet_start)) { h1 { font-size: 36px; } h2 { font-size: 28px; } h3 { font-size: 26px; } h4 { font-size: 22px; } } p { font-size: 16px; margin: 0 0 var(--space_l); } strong, b { font-weight: var(--weight_bold); } em, i { font-style: italic; } a { color: var(--gray_7); transition: color 0.4s ease; text-decoration: underline var(--cnn_red); -webkit-text-decoration-color: var(--cnn_red); } a:hover { text-decoration: none; color: var(--cnn_red); } a:hover { text-decoration: underline; } blockquote { border-left: 2px solid var(--cnn_red); padding-left: var(--space_m); margin: 0 0 var(--space_l); } q { display: block; margin-bottom: var(--space_l); font-size: 26px; font-weight: var(--weight_light); line-height: var(--line_height_lg); } q:before { display: block; width: 36px; height: 36px; margin-bottom: var(--space_xs); background: url(\"data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNjQiIGhlaWdodD0iNjQiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiPjxkZWZzPjxwYXRoIGQ9Ik00Ni45OTEgMjguMDAzaDExLjAxVjUySDM0VjMzLjE3OWwuMDE4LS4wNjNDMzQuMTE1IDI0LjM4IDQxLjA1NCAxNC42OTQgNTAuMjc0IDEybDEuNjU0IDIuODg5Yy0zLjc3NSAzLjQ1Ny00Ljg4NCA5LjEzNC00LjkzNyAxMy4wNjR2LjA1em0tMjgtLjA1di4wNWgxMS4wMVY1Mkg2VjMzLjE4bC4wMTgtLjA2NEM2LjExNSAyNC4zOCAxMy4wNTQgMTQuNjk0IDIyLjI3NCAxMmwxLjY1NCAyLjg5Yy0zLjc3NSAzLjQ1Ni00Ljg4NCA5LjEzMi00LjkzNyAxMy4wNjN6IiBpZD0iYSIvPjwvZGVmcz48ZyBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPjxtYXNrIGlkPSJiIiBmaWxsPSIjZmZmIj48dXNlIHhsaW5rOmhyZWY9IiNhIi8+PC9tYXNrPjx1c2UgZmlsbD0iI2NjMDAwMCIgeGxpbms6aHJlZj0iI2EiLz48ZyBtYXNrPSJ1cmwoI2IpIiBmaWxsPSIjY2MwMDAwIj48cGF0aCBkPSJNMCAwaDY0djY0SDB6Ii8+PC9nPjwvZz48L3N2Zz4=\") no-repeat center center/cover; content: \"\"; } /* Lists */ ul { list-style-type: square; } ul, ol { padding: 0; margin: 0 14px var(--space_l); } li { margin: 0 var(--space_2xs) var(--space_s); } li:last-child { padding-bottom: 0; } /* Other */ hr { border: 0; height: 1px; background: var(--gray_4); } mark { background-color: #ffea9b; }        /* NOTE: default styles */ body { opacity: 0; font-family: CNN, Helvetica Neue, Helvetica, Arial, sans-serif; font-size: 18px; font-style: normal; line-height: 26px; color: #262626; font-variant: normal; font-weight: 300; background-color: #FAFAFA; -webkit-font-smoothing: antialiased; -ms-text-size-adjust: 100%; -webkit-text-size-adjust: 100%; } .l-full-width { padding: 0 10px; } .l-max-width { max-width: 780px; background-color: #FFF; padding-bottom: 25px; margin: 0 auto; } .l-full-width>*, .l-standard-top { margin-top: 15px; } .l-small-top { margin-top: 10px; } .l-big-top { margin-top: 25px; } .pg-headline { font-weight: bold; margin-bottom: 10px; } .pg-headline.pg-headline__indicator { margin-top: 5px; } .byline-text { color: #737373; font-weight: 500; font-size: 12px; line-height: 1.33; margin: 0; } .byline-text a { color: #262626; text-decoration: none; } .byline-timestamp { font-size: 12px; font-weight: 500; line-height: 1.63; color: #737373; } .m-light-grey { color: #737373; } .m-soft-grey { color: #595959; } .m-heavy { font-weight: 500; } .m-font-small { font-size: 14px; line-height: 20px; } ul { list-style-position: inside; margin: 0; padding: 0; } li.el_storyhighlights_item { border-top-style: solid; border-top-width: 1px; border-top-color: #E6E6E6; list-style-type: none; padding: 10px 0; color: rgb(38, 38, 38); font-weight: 400; -webkit-font-smoothing: antialiased; font-size: .9333333333rem; line-height: 1.4285714286; } li.el_storyhighlights_item:last-of-type { padding-bottom: 0; } .carousel-filmstrip button { background: transparent; border: 3px solid transparent; height: 55px; max-width: 60px; outline: none; padding: 0; width: 55px; } .carousel-filmstrip button.active amp-img { border-bottom: 3px solid #c00; } .carousel-filmstrip button.inactive amp-img { border-bottom: 3px solid transparent; } .amp-scrollable-carousel-slide { margin-left: 5px; } .el_gallery > amp-carousel .amp-carousel-button { background: transparent; outline: none; } .el_gallery > amp-carousel .amp-carousel-button.amp-disabled { opacity: .5; visibility: visible; } .el_gallery > amp-carousel .amp-carousel-button-prev { background-size: 34px 34px; background-image: url(\\'data:image/svg+xml;charset=utf-8,<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"50\" height=\"50\" viewBox=\"0 0 50 50\"><path d=\"M 25 0 L 0 25 L 25 50 L 30 50 L 30 50 L 5 25 L 30 0 L 30 0 Z\" fill=\"#595959\"/></svg>\\'); filter: drop-shadow(0 2px 1px rgba(0, 0, 0, .3)); left: 5px; -webkit-filter: drop-shadow(0 2px 1px rgba(0, 0, 0, .3)); } .el_gallery > amp-carousel .amp-carousel-button-next { background-size: 34px 34px; background-image: url(\\'data:image/svg+xml;charset=utf-8,<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"50\" height=\"50\" viewBox=\"0 0 50 50\"><path d=\"M 25 0 L 0 25 L 25 50 L 30 50 L 30 50 L 5 25 L 30 0 L 30 0 Z\" fill=\"#595959\"/></svg>\\'); filter: drop-shadow(0 -2px 1px rgba(0, 0, 0, .3)); right: 5px; transform: translateY(-50%) rotate(180deg); -webkit-transform: translateY(-50%) rotate(180deg); -webkit-filter: drop-shadow(0 -2px 1px rgba(0, 0, 0, .3)); } .el_gallery_title { font-size: 16px; font-weight: 300; line-height: 1.5em; margin: 10px 0; } .el_gallery_title span:before { content: \\'Photos: \\'; font-weight: 500; } .el_gallery-filmstrip-wrapper { padding: 10px 0; } .el_gallery-filmstrip-wrapper .amp-carousel-button { background-color: rgba(89, 89, 89, 0.5); height: 25px; outline: none; width: 25px; } .el_gallery-filmstrip-wrapper .amp-carousel-button-prev { background-size: 15px 15px; background-image: url(\\'data:image/svg+xml;charset=utf-8,<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"50\" height=\"50\" viewBox=\"0 0 50 50\"><path d=\"M 25 0 L 0 25 L 25 50 L 30 50 L 30 50 L 5 25 L 30 0 L 30 0 Z\" fill=\"#fff\"/></svg>\\'); background-position: 70% 50%; left: 0px; } .el_gallery-filmstrip-wrapper .amp-carousel-button-next { background-size: 15px 15px; background-image: url(\\'data:image/svg+xml;charset=utf-8,<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"50\" height=\"50\" viewBox=\"0 0 50 50\"><path d=\"M 25 0 L 0 25 L 25 50 L 30 50 L 30 50 L 5 25 L 30 0 L 30 0 Z\" fill=\"#fff\"/></svg>\\'); background-position: 70% 50%; right: 0px; transform: translateY(-50%) rotate(180deg); -webkit-transform: translateY(-50%) rotate(180deg); } .el_gallery-meta { align-items: center; border-bottom: 1px solid #d9d9d9; display: flex; overflow: hidden; padding: 10px 0; } .el_gallery-meta > p { color: #595959; flex-grow: 1; font-weight: 700; font-size: 12px; line-height: 1em; margin: 0; padding: 0; } .el_gallery-slide-caption { color: #595959; line-height: 1.5em; font-size: 16px; font-weight: 300; margin: 10px 0; min-height: 1.5em; -webkit-font-smoothing: antialiased; } .el_gallery-caption-showhide { align-items: center; background: transparent; border: none; color: #595959; display: flex; font-weight: 500; outline: none; } .el_gallery-caption-showhide .showhide_text { margin-right: 10px; } .el_gallery-caption-showhide .showhide_icon { display: inline-block; width: 12px; height: 12px; background-size: 12px 12px; background-image: url(\\'data:image/svg+xml;charset=utf-8,<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"50\" height=\"50\" viewBox=\"0 0 50 50\"><path d=\"M 35 0 L 10 25 L 35 50 L 30 50 L 40 50 L 15 25 L 40 0 L 30 0 Z\" fill=\"#262626\"/></svg>\\'); background-position: 50% 50%; } .el_gallery-caption-showhide .showhide_icon.show { transform: rotate(270deg); -webkit-transform: rotate(270deg); } .el_gallery-caption-showhide .showhide_icon.hide { transform: rotate(90deg); -webkit-transform: rotate(90deg); } .el-editorial-source { font-weight: 500; font-style: normal; } .el-editorial-source:after { content: \" — \"; } .el_relatedarticle_wrapper { margin-bottom: 10px; } .el_relatedarticle_caption { color: #595959; margin-top: 10px; } .el_relatedarticle_caption a span { color: #595959; font-size: 16px; line-height: 20px; } .el_relatedarticle_caption a span:before { content: \"Related Article: \"; font-weight: 500; } .el_relatedarticle_caption a:hover span { color: #2483b3; } .body_text { line-height: 30px; } .body_text>* { margin: 15px 0; } .body_text h3 { font-size: 26px; line-height: 30px; font-weight: 300; } .ad-wrapper, .livestory-ad-wrapper { text-align: center; height: 250px; } ul.l-list--unordered { margin-left: 4%; } .footer .footer-links { font-size: .7em; margin-top: 0; } .m-legal__links[data-analytics=footer_adchoices] { display: inline-block; padding-right: 20px; position: relative; } .m-legal__links[data-analytics=footer_adchoices]:after { background: url(https://amp.cnn.com/static/sprite.png) no-repeat 0 -153px; content: \\'\\'; display: block; margin-top: -6px; height: 12px; width: 12px; position: absolute; top: 50%; right: 3px; padding: 0; } .m-separator { width: 100%; height: 1px; border: 0; background: #d9d9d9; margin: 0; } .m-closing-accent { width: 20px; height: 1px; border: 0; background: #737373; margin: 0; } .l-ratio-container { position: relative; width: 100%; padding-top: 56.25%; } .l-ratio-container .inner { position: absolute; top: 0; left: 0; right: 0; bottom: 0; } .l-ratio-container .inner > * { width: 100%; height: 100%; } .m-float-left { float: left; } .m-marginless { margin: 0; } .m-line-heightless { line-height: 0; } .m-bump-right { margin-right: .25em; } .amp-mode-mouse .l-hide-on-desktop { display: none; } .image-captions, .image-credits { color: #aaa; font-size: 14px; margin-bottom: 0; } .image-credits:before { content: \\'\\'; height: 6px; width: 6px; background-color: #c00; display: inline-block; position: relative; bottom: 2px; margin: 0 6px; } .image-credits > span + span:before { content: \"/ \"; } .body_text .button { background: #2370FD; font-size: 18px; color: #F1F1F1; display: block; text-align: center; margin: 20px 10px; padding: 10px 0; } .body_text .button a { color: #F1F1F1; text-decoration: none; } .body_text a, .footer a { color: #006598; text-decoration: none; } .footer .footer-copyright, .amp-img { margin-bottom: 0; } .smartlink-banner { margin: 0 auto; text-align: center; } .smartlink-image { margin: 0 auto; } .interactive-content-placeholder { height: 60px; margin: 20px auto; background: #FEFEFE; text-align: left; color: #2370FD; line-height: 27px; border-radius: 8px; border: 1px solid #A6A6A6; display: flex; align-items: center; } .interactive-content-center { margin: 0 auto; } .interactive-content-icon { background-image: url(\\'data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"36\" height=\"36\" viewBox=\"0 0 36 36\" version=\"1.1\"><g stroke=\"none\" stroke-width=\"1\" fill=\"none\" fill-rule=\"evenodd\"><g fill=\"#2370FD\"><path d=\"M1.2 24.3C0.4 22.4 0 20.3 0 18 0 8.1 8.1 0 18 0 20.3 0 22.4 0.4 24.3 1.2L19.5 3.7C19 3.6 18.5 3.6 18 3.6 10.1 3.6 3.6 10.1 3.6 18 3.6 18.5 3.6 19.1 3.6 19.5L1.2 24.3 1.2 24.3 1.2 24.3ZM21.6 25L2.4 35C1.5 35.4 0.6 34.5 1 33.6L11.3 13.8C12 12.5 12.9 11.7 14.3 11L33.6 1C34.5 0.6 35.4 1.5 35 2.4L25 21.7C24.2 23.2 23.4 24.2 21.6 25L21.6 25 21.6 25ZM22.4 19.2L28.1 7.9 16.3 14C15 14.7 14.7 15.4 14.7 15.4L20.4 21.2C20.4 21.2 21.7 20.5 22.4 19.2L22.4 19.2 22.4 19.2ZM34.8 11.7L32.4 16.5C32.4 17 32.4 17.5 32.4 18 32.4 26 26 32.4 18 32.4 17.5 32.4 17 32.4 16.5 32.4L11.7 34.8C13.7 35.6 15.8 36 18 36 27.9 36 36 27.9 36 18 36 15.8 35.6 13.7 34.8 11.7L34.8 11.7 34.8 11.7Z\"/></g></g></svg>\\'); width: 36px; height: 36px; float: left; margin: 3px 0 0 20px; } .interactive-content-placeholder a { float: left; display: block; font-size: 18px; line-height: 22px; margin-left: 20px; width: 200px; } .editors-note { font-size: 12px; line-height: 18px; font-style: italic; } .editors-note span { color: #737373; font-weight: 700; } amp-instagram { margin-bottom: 0; } .l-instagram-caption { background: rgba(237, 238, 239, 0.5); color: #a5a9ac; font-size: .8em; line-height: 1.5em; margin: 0; padding: 5px 10px; } /*.cite { }*/ /* NOTE: nav styles */ .nav { background-color: #1A1A1A; height: 50px; margin-bottom: 10px; position: relative; z-index: 20000; } .nav-condensed { margin-bottom: 0; } .nav-logo { background-image: url(https://cdn.cnn.com/cnn/2016/images/01/28/logo_cnn_badge_2up.png); background-position: 0 0; background-repeat: no-repeat; background-size: 60px; height: 60px; position: absolute; width: 60px; z-index: 33; top: 0; left: 0; } .nav a { color: inherit; display: inline-block; text-decoration: none; } .nav-section__name { color: #bfbfbf; cursor: pointer; display: inline-block; left: 70px; line-height: 50px; position: relative; } .nav-section__name a { -webkit-transition: color .2s; transition: color .2s; } .page--nav-open .nav-menu { display: block; overflow: auto; } .nav-menu { background-color: #262626; color: #fff; font-size: 18px; line-height: 21px; padding: 15px 0 1px 10px; /*margin-top: 6.5rem;*/ width: 100%; height: 90%; } .nav-menu-close-button { background: none; border: 0 none; outline: none; color: #fff; font-size: 21px; transform: scale(1,.8); -webkit-transform: scale(1,.8); -moz-transform: scale(1,.8); -ms-transform: scale(1,.8); -o-transform: scale(1,.8); } .nav-menu ul { list-style:none; margin: 0 0 40px 0; overflow-y: scroll; } .nav-menu li { text-align: right; margin: 0 13px 10px 0; } .nav-menu ul li a { text-decoration: none; color: #fff; } .nav-button { background-color: #262626; float: right; padding: 10px 15px; display: inline-block; cursor: pointer; height: 50px; outline: none; border: 0 none; } .nav-button:before { content: \"\"; width: 25px; height: 4px; display: block; border-top: 10px double #fff; border-bottom: 3px solid #fff; } .nav__live-tv { display: inline; margin-right: 10px; border: 1px solid #bfbfbf; font-size: .9em; font-weight: 300; letter-spacing: .05em; line-height: 23px; padding: 0 10px; position: absolute; right: 50px; top: 13px; -webkit-transition: color .2s,border-color .2s; transition: color .2s,border-color .2s; } .nav .nav__live-tv { color: #fff; } .nav__live-tv-icon { background: #c00; border-radius: 10px; display: inline-block; height: 7px; margin: 0 0 2px 5px; vertical-align: middle; width: 7px; } .hamburger-wrapper { width: 50px; height: 50px; display: inline-block; float: right; overflow: hidden; } /* NOTE: Temp. hot fix for nav hamburger icon */ .hamburger-wrapper span, .hamburger-wrapper span:before, .hamburger-wrapper span:after { height: 3px; width: 22px; background: white; position: absolute; display: block; content: \\'\\'; } .hamburger-wrapper span { right: 24px; top: 25px; } .hamburger-wrapper span:before { top: -6px; } .hamburger-wrapper span:after { bottom: -6px; } .politics-theme .hamburger-wrapper span, .politics-theme .hamburger-wrapper span:before, .politics-theme .hamburger-wrapper span:after { background-color: #a6a6a6; } /* NOTE: amp-app-banner styles */ .amp-banner { align-items: center; display: flex; justify-content: center; width: 100%; } .amp-banner > .amp-banner-logo { padding: 8px; } .amp-banner > .amp-banner-text { flex: 1; font-size: 18px; padding: 0 8px; } .amp-banner .action-btn { background-color: #fff; cursor: pointer; font-family: inherit; font-size: 1rem; line-height: 1.125rem; margin-right: 1rem; padding: .7em .8em; text-decoration: none; text-transform: uppercase; vertical-align: middle; white-space: nowrap; word-wrap: normal; } .amp-banner .action-btn.btn-cnn { border: 1px solid #cb0000; color: #cb0000; } .amp-banner .action-btn.btn-money { border: 1px solid #0666a7; color: #0666a7; } /*.nav-menu__hamburger { margin: -1.5px 0 0 -10px; -webkit-transition: background .3s, color .2s; transition: background .3s, color .2s; position: absolute; top: 50%; right: 5%; z-index: 32; outline: none; border: none; border-radius: 0; -webkit-appearance: none; -moz-appearance: none; appearance: none; }*/ /* NOTE: nav & sidebar styles */ /*#sidebar[aria-hidden=\"true\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger, #sidebar[aria-hidden=\"true\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger:after, #sidebar[aria-hidden=\"true\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger:before, #sidebar[aria-hidden=\"false\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger, #sidebar[aria-hidden=\"false\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger:after, #sidebar[aria-hidden=\"false\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger:before { background: #a6a6a6; height: 3px; width: 20px; } #sidebar[aria-hidden=\"true\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger, #sidebar[aria-hidden=\"true\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger:after, #sidebar[aria-hidden=\"true\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger:before { background: #fff; } .politics-theme #sidebar[aria-hidden=\"true\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger, .politics-theme #sidebar[aria-hidden=\"true\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger:after, .politics-theme #sidebar[aria-hidden=\"true\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger:before { background: #a6a6a6; } #sidebar[aria-hidden=\"true\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger:after, #sidebar[aria-hidden=\"true\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger:before, #sidebar[aria-hidden=\"false\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger:after, #sidebar[aria-hidden=\"false\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger:before { content: \\'\\'; -webkit-transform-origin: center center; -ms-transform-origin: center center; transform-origin: center center; -webkit-transition: background .3s, -webkit-transform .3s; transition: background .3s, -webkit-transform .3s; transition: transform .3s, background .3s; transition: transform .3s, background .3s, -webkit-transform .3s; } #sidebar[aria-hidden=\"true\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger:before, #sidebar[aria-hidden=\"false\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger:before { position: absolute; top: -6px; left: 0; } #sidebar[aria-hidden=\"true\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger:after, #sidebar[aria-hidden=\"true\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger:before { content: \\'\\'; -webkit-transform-origin: center center; -ms-transform-origin: center center; transform-origin: center center; -webkit-transition: background .3s,-webkit-transform .3s; transition: background .3s,-webkit-transform .3s; transition: transform .3s,background .3s; transition: transform .3s,background .3s,-webkit-transform .3s; } #sidebar[aria-hidden=\"true\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger:after, #sidebar[aria-hidden=\"false\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger:after { position: absolute; bottom: -6px; left: 0; } #sidebar[aria-hidden=\"false\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger { background: transparent; } #sidebar[aria-hidden=\"false\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger:before, #sidebar[aria-hidden=\"false\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger:after { background: #c00; }*/ /* rotation of elements */ /*#sidebar[aria-hidden=\"false\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger:before { -webkit-transform: translateY(6px) rotate(-45deg); -ms-transform: translateY(6px) rotate(-45deg); transform: translateY(6px) rotate(-45deg); } #sidebar[aria-hidden=\"false\"] ~ .l-max-width .nav .hamburger-wrapper .nav-menu__hamburger:after { -webkit-transform: translateY(-6px) rotate(45deg); -ms-transform: translateY(-6px) rotate(45deg); transform: translateY(-6px) rotate(45deg); }*/ /* yieldmo specific amp-ad container styles */ .ad-container { display: flex; justify-content: center; } /*Social Share bar styles */ amp-social-share { background-size: 34px; border-radius: 50%; margin: 0 0 0 8px; } .social-share-bar { padding: 5px 0 0; width: 100%; } /* Underscored theme styles */ .underscored-theme { font-family: \\'CNN\\', \\'Helvetica Neue\\', Helvetica, Arial, sans-serif; } .underscored-theme p a { background-image: linear-gradient(to bottom, #6a29d5 0%, #6a29d5 100%); background-position: bottom; background-repeat: no-repeat; background-size: 1% 0; color: #6a29d5; font-weight: 500; position: relative; text-decoration: none; transition: background-size 0.1s linear; } .underscored-theme p a:hover { background-size: 100% 2px; } .underscored-theme h1, .underscored-theme h2, .underscored-theme h3, .underscored-theme h4, .underscored-theme h5, .underscored-theme h6 { color: #0a0a0a; font-weight: bold; } .underscored-theme h1 { font-size: 32px; line-height: 1.075; } .underscored-theme h2 { font-size: 28px; line-height: 1.125; } .underscored-theme h3 { font-size: 26px; line-height: 1.2; } .underscored-theme h4 { font-size: 32px; line-height: 1.187; } .underscored-theme h5 { font-size: 26px; line-height: 1.154; } .underscored-theme h6 { font-size: 18px; line-height: 1.111; } .underscored-theme .nav { background-color: transparent; display: flex; padding: 20px 10px; } .underscored-theme .logo-container { display: flex; flex: 1; width: 245px; } .underscored-theme .nav-logo { background: url(\\'https://cdn.cnn.com/cnn/2018/images/03/29/cnn-black_badge.png\\') no-repeat; background-size: 50px; position: relative; height: 50px; width: 50px; } .underscored-theme .underscored-logo { background: url(\\'https://cdn.cnn.com/cnn/2018/images/03/29/underscored-logo.png\\') no-repeat center; background-size: 188px; height: 50px; margin-left: 7px; width: 188px; } .underscored-theme .hamburger-wrapper { position: relative; top: 12px; height: 21px; width: 26px; } .underscored-theme .hamburger-wrapper span { background: url(\\'data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"26\" height=\"21\" viewBox=\"0 0 26 21\"><path fill=\"#0A0A0A\" d=\"M23.35 4.11H1.98A1.993 1.993 0 0 1 0 2.133v-.053C0 .997.897.1 1.979.1H23.35c1.082 0 1.979.897 1.979 1.979v.053a1.993 1.993 0 0 1-1.98 1.979zm1.98 6.016v-.052a1.993 1.993 0 0 0-1.98-1.98H1.98A1.993 1.993 0 0 0 0 10.075v.052c0 1.082.897 1.98 1.979 1.98H23.35a1.993 1.993 0 0 0 1.979-1.98zm0 7.995v-.053a1.993 1.993 0 0 0-1.98-1.979H1.98A1.993 1.993 0 0 0 0 18.07v.052C0 19.203.897 20.1 1.979 20.1H23.35a1.993 1.993 0 0 0 1.979-1.979z\"></path></svg>\\') no-repeat; height: 21px; left: auto; position: relative; right: auto; top: auto; width: 26px; } .underscored-theme .hamburger-wrapper span:before, .underscored-theme .hamburger-wrapper span:after { content: none; } .underscored-theme .pg-headline { color: #0a0a0a; font-size: 32px; font-weight: 700; } .underscored-theme .byline-text, .underscored-theme .byline-timestamp { color: #a6a6a6; font-weight: 700; font-size: 12px; margin: 0; } .underscored-theme .el_gallery > amp-carousel .amp-carousel-button-prev { background-image: url(\\'data:image/svg+xml;charset=utf-8,<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"50\" height=\"50\" viewBox=\"0 0 50 50\"><path d=\"M 25 0 L 0 25 L 25 50 L 30 50 L 30 50 L 5 25 L 30 0 L 30 0 Z\" fill=\"#fff\"/></svg>\\'); } .underscored-theme .el_gallery > amp-carousel .amp-carousel-button-next { background-image: url(\\'data:image/svg+xml;charset=utf-8,<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"50\" height=\"50\" viewBox=\"0 0 50 50\"><path d=\"M 25 0 L 0 25 L 25 50 L 30 50 L 30 50 L 5 25 L 30 0 L 30 0 Z\" fill=\"#fff\"/></svg>\\'); } .underscored-theme .el_gallery-slide-caption { margin: 20px 0; } .underscored-theme .el_gallery-filmstrip-wrapper { padding: 20px 0; } .underscored-theme .carousel-filmstrip button.active { border-color: #6a29d5; } .underscored-theme .carousel-filmstrip button.active amp-img { border-bottom: 3px solid #6a29d5; } .underscored-theme .el_gallery-meta { border-bottom: 1px solid #a6a6a6; } .underscored-theme .el_gallery-meta > p { font-size: 14px; } .underscored-theme .el_storyhighlights_wrapper > .el_headline { color: #0a0a0a; font-size: 18px; font-weight: 700; line-height: 20px; margin: 10px 0 20px 0; padding: 3px 0; } .underscored-theme li.el_storyhighlights_item { border-top: 1px solid #cdcdcd; font-size: 14px; line-height: 22px; font-weight: 500; margin: 0; padding: 10px 0 20px; } .underscored-theme .disclaimer-copy { background-color: #F2F2F2; color: #595959; font-size: 12px; line-height: 22px; padding: 20px; } .underscored-theme .disclaimer-copy a { color: #595959; font-weight: 700; } .underscored-theme .body_text a, .underscored-theme .footer a { color: #6a29d5; text-decoration: none; } .underscored-theme .body_text .button { background: #2370FD; color: #F1F1F1; }        body.politics-theme {\\n            background-color: #E6E6E6;\\n        }\\n        .politics-theme .nav {\\n            background: #f2f2f2;\\n        }\\n        .politics-theme .nav-logo {\\n            background: url(\\'https://ssl.cdn.turner.com/cnn/2016/images/01/28/logo_politics_sm_header.png\\') no-repeat;\\n            background-size: auto 50px;\\n            width: 175px;\\n            height: 50px;\\n        }\\n        .politics-theme .nav .nav__live-tv {\\n            color: #3d3d3d;\\n            border: 1px solid #3d3d3d;\\n        }\\n\\n        .politics-theme .carousel-filmstrip button.active amp-img {\\n            border-bottom: 3px solid #1a6aff;\\n        }\\n\\n        #sidebar[open] .menuicon span::before {\\n            content: \\'x\\';\\n            background: blue;\\n            width: 200px;\\n            height: 200px;\\n        }\\n\\n        .menuicon span::after, .menuicon span::before {\\n            content: \\'x\\';\\n        }\\n    </style>\\n  </head>\\n  <body class=\"politics-theme\">\\n          <amp-app-banner layout=\"nodisplay\"\\n          class=\"amp-banner\" id=\"amp-banner-cnn\">\\n              <div class=\"amp-banner-logo\">\\n                  <amp-img src=\"/static/cnn-app-banner-icon.png\"\\n                    width=\"50\"\\n                    height=\"43\"\\n                    layout=\"fixed\"></amp-img>\\n              </div>\\n      \\n              <div class=\"amp-banner-text\">\\n                  Read more news from CNN\\n              </div>\\n      \\n              <div class=\"amp-banner-action\">\\n                  <button class=\"action-btn btn-cnn\" open-button>View in App</button>\\n              </div>\\n          </amp-app-banner>\\n      <div class=\"m-float-left\">\\n          <amp-iframe width=1 height=1\\n                      src=\"https://sdc.cnn.com/analytics/cnn/stats.html?canonical_url=https://www.cnn.com/2019/11/26/politics/trump-cnn-impeachment-poll/index.html&author=Analysis by Chris Cillizza, CNN Editor-at-large&template_type=content%3Avideo%3Acollection&type_amp=google amp&section=politics&subsection=&vertical=politics&cap_topic=9C7,3T9,3VT,5NC,7WN,86P,BPP,DBJ,DHX,BW0,3T6S&&cepTopics=%7B%2215HT%22%3A%22cep_iabt%22%2C%2215H4%22%3A%22cep_iabt%22%2C%2216BC%22%3A%22cep_sent%22%2C%229C7%22%3A%22cep_tags%22%2C%223T9%22%3A%22cep_tags%22%2C%223TLB%22%3A%22cep_tags%22%2C%222JP5%22%3A%22cep_tags%22%2C%225NC%22%3A%22cep_tags%22%2C%2286P%22%3A%22cep_tags%22%2C%223TLC%22%3A%22cep_tags%22%2C%222PC9%22%3A%22cep_tags%22%2C%22DHX%22%3A%22cep_tags%22%2C%22BW0%22%3A%22cep_tags%22%2C%223T6S%22%3A%22cep_tags%22%2C%2245Z%22%3A%22cep_tags%22%2C%22DBJ%22%3A%22cep_tags%22%2C%222PCG%22%3A%22cep_tags%22%2C%222PCF%22%3A%22cep_tags%22%2C%223VT%22%3A%22cep_tags%22%2C%22BPP%22%3A%22cep_tags%22%2C%225G8%22%3A%22cep_tags%22%2C%227WN%22%3A%22cep_tags%22%2C%22DG2%22%3A%22cep_tags%22%7D\"\\n                      sandbox=\"allow-scripts allow-same-origin\"\\n                      layout=\"fixed\"\\n                      frameborder=\"0\">\\n              <amp-img src=\"https://sdc.cnn.com/analytics/cnn/pixel.gif\" height=1 width=1 layout=\"fill\" placeholder></amp-img>\\n          </amp-iframe>\\n      </div>\\n      \\n      <amp-analytics type=\"segment\">\\n          <script type=\"application/json\">\\n              {\\n                  \"vars\": {\\n                      \"writeKey\": \"r0ko3qzY2kIjPvSmCFsKmht9Pzu1KWhM\",\\n                          \"name\": \"https://www.cnn.com/2019/11/26/politics/trump-cnn-impeachment-poll/index.html\"\\n                  }\\n              }\\n          </script>\\n      </amp-analytics>\\n      \\n      <amp-analytics type=\"chartbeat\">\\n          <script type=\"application/json\">\\n              {\\n                  \"vars\": {\\n                      \"uid\": \"37612\",\\n                      \"domain\": \"cnn.com\",\\n                      \"sections\": \"politics,bra-the-point,art-vid-vls-col,col-politics-of-the-day\"\\n                  }\\n              }\\n          </script>\\n      </amp-analytics>\\n          <amp-sidebar id=\"sidebar\"\\n             layout=\"nodisplay\"\\n             side=\"right\"\\n             class=\"nav-menu\"\\n             width=\"100vw\">\\n             <ul>\\n                <li><amp-img class=\\'amp-close-image\\'\\n                      src=\"/static/close-x.png\"\\n                      width=\"20\"\\n                      height=\"20\"\\n                      alt=\"close sidebar\"\\n                      on=\"tap:sidebar.close\"\\n                      role=\"button\"\\n                      tabindex=\"0\"></amp-img></li>\\n                  <li><a href=\"https://www.cnn.com/\">Home</a></li>\\n                  <li><a href=\"https://www.cnn.com/us/\">U.S.</a></li>\\n                  <li><a href=\"https://www.cnn.com/world/\">World</a></li>\\n                  <li><a href=\"https://www.cnn.com/politics/\">Politics</a> </li>\\n                  <li><a href=\"https://www.cnn.com/business\">Business</a></li>\\n                  <li><a href=\"https://www.cnn.com/opinions/\">Opinion</a></li>\\n                  <li><a href=\"https://www.cnn.com/health/\">Health</a></li>\\n                  <li><a href=\"https://www.cnn.com/entertainment\">Entertainment</a></li>\\n                  <li><a href=\"https://www.cnn.com/tech/\">Tech</a></li>\\n                  <li><a href=\"https://www.cnn.com/style/\">Style</a></li>\\n                  <li><a href=\"https://www.cnn.com/travel\">Travel</a></li>\\n                  <li><a href=\"https://m.bleacherreport.com/\">Bleacher</a></li>\\n                  <li><a href=\"https://www.cnn.com/living/\">Living</a></li>\\n                  <li><a href=\"https://www.cnn.com/videos/\">Videos</a></li>\\n                  <li><a href=\"https://edition.cnn.com\">International</a></li>\\n                  <li><a href=\"//cnn.it/go2\">Live TV</a></li>\\n              </ul>\\n          </amp-sidebar>\\n      <div class=\"l-max-width\">\\n              <nav class=\"nav \">\\n                  <a href=\"https://www.cnn.com/\" id=\"logo\" class=\"nav-logo\"></a>\\n                   \\n                  <a href=\"https://cnn.it/go2\" data-header=\"live\" class=\"js-nav__live-tv nav__live-tv\" id=\"nav-mobileTV\">Live TV <i class=\"nav__live-tv-icon\"></i></a>\\n                  <!-- <div class=\"hamburger-wrapper\"><input type=\"checkbox\" on=\\'tap:sidebar.toggle\\' class=\"nav-menu__hamburger\" tabindex=\"0\" role=\"button\" /></div> -->\\n                  <div class=\"hamburger-wrapper\" on=\"tap:sidebar.toggle\" tabindex=\"0\" role=\"button\">\\n                    <span class=\"nav-menu__hamburger\"></span>\\n                  </div>\\n              </nav>\\n          <div class=\"l-full-width\">\\n              <h1 class=\"pg-headline l-big-top \">No, the new CNN poll is not good news for Donald Trump on impeachment</h1>\\n              <div class=\"byline-wrapper m-light-grey m-font-small l-small-top\">\\n                          <div class=\"byline-text m-heavy\">Analysis by Chris Cillizza, CNN Editor-at-large <br/> </div>\\n                      <div class=\"byline-timestamp l-small-top\">Updated 4:18 PM EST, Tue November 26, 2019</div>\\n                      <div class=\"social-share-bar\">\\n                        <amp-social-share type=\"facebook\" data-param-app_id=\"80401312489\" height=\"40\" width=\"40\"></amp-social-share>\\n                        <amp-social-share type=\"twitter\" height=\"40\" width=\"40\"></amp-social-share>\\n                      </div>\\n              </div>\\n                      \\n                      \\n                                              <amp-iframe\\n                                                  width=\"768\"\\n                                                  height=\"432\"\\n                                                  frameborder=\"0\"\\n                                                  layout=\"responsive\"\\n                                                  sandbox=\"allow-scripts allow-same-origin allow-popups\"\\n                                                  allowfullscreen\\n                                                  src=\"https://fave.api.cnn.io/v1/amp/?video&#x3D;politics/2019/11/26/trump-impeachment-poll-steady-results-enten-newday-vpx.cnn&canonical_url=https://www.cnn.com/2019/11/26/politics/trump-cnn-impeachment-poll/index.html&ssid=cnn.com_mobile_mobileweb_thepoint&seconds=261&videoId=politics%2F2019%2F11%2F26%2Ftrump-impeachment-poll-steady-results-enten-newday-vpx.cnn&imageUrl=https://cdn.cnn.com/cnnnext/dam/assets/191126070700-cnn-poll-1126-super-169.jpg&autoplay=&headline=Poll shows support for impeachment remains steady&section=politics&source=cnn&videoCollection=true&id=&customer=cnn&edition=domestic&env=prod&path=/2019/11/26/politics/trump-cnn-impeachment-poll/index.html&videoCollectionSlug=politics-of-the-day&cepTopics=%7B%2215HT%22%3A%22cep_iabt%22%2C%2215H4%22%3A%22cep_iabt%22%2C%2216BC%22%3A%22cep_sent%22%2C%229C7%22%3A%22cep_tags%22%2C%223T9%22%3A%22cep_tags%22%2C%223TLB%22%3A%22cep_tags%22%2C%222JP5%22%3A%22cep_tags%22%2C%225NC%22%3A%22cep_tags%22%2C%2286P%22%3A%22cep_tags%22%2C%223TLC%22%3A%22cep_tags%22%2C%222PC9%22%3A%22cep_tags%22%2C%22DHX%22%3A%22cep_tags%22%2C%22BW0%22%3A%22cep_tags%22%2C%223T6S%22%3A%22cep_tags%22%2C%2245Z%22%3A%22cep_tags%22%2C%22DBJ%22%3A%22cep_tags%22%2C%222PCG%22%3A%22cep_tags%22%2C%222PCF%22%3A%22cep_tags%22%2C%223VT%22%3A%22cep_tags%22%2C%22BPP%22%3A%22cep_tags%22%2C%225G8%22%3A%22cep_tags%22%2C%227WN%22%3A%22cep_tags%22%2C%22DG2%22%3A%22cep_tags%22%7D&isLive=false\">\\n                                              <amp-img alt=\"article video\" layout=\"fill\" src=\"https://cdn.cnn.com/cnnnext/dam/assets/191126070700-cnn-poll-1126-super-169.jpg\" placeholder></amp-img>\\n                                              </amp-iframe>\\n                      \\n                      \\n              <div class=\"pg-side-of-rail\">\\n                  <div class=\"l-container\">\\n                  </div>\\n                      <div class=\"el_leafmedia l-big-top\">\\n                          <div class=\"body_text\">\\n                                  \\n                                  \\n                                  <p></p>\\n                                  \\n                                  \\n                                  <p><cite class=\"m-line-heightless el-editorial-source\">(CNN)</cite> A<a href=\"http://cdn.cnn.com/cnn/2019/images/11/25/rel13a.-.trump,.impeachment.pdf\" target=\"_blank\"> new CNN poll</a> shows that half the country believes that President Donald Trump should be not only impeached by the House, but also removed from office by the Senate.</p>\\n                                  \\n                                  \\n                                  <p>That result is being spun in some corners of the internet as great news for Trump, because that 50% number is unchanged from a CNN poll in mid-October, the conclusion being that the last 10 days of public impeachment hearings have not convinced more of the public that the President needs to go.</p>\\n                                  \\n                                  \\n                                  \\n                                  \\n                                  \\n                                  <p>Except that we are missing the forest for the trees here: A majority of the country believes the current President of the United States should be impeached and removed from office!</p>\\n                                  <div class=\"ad-wrapper\">\\n                                      <amp-ad\\n                                          width=300\\n                                          height=250\\n                                          type=\"doubleclick\"\\n                                          data-loading-strategy=\"prefer-viewability-over-views\"\\n                                          data-slot=\"/8663477/CNN/politics/leaf/vls\"\\n                                          data-account=\"f7c6e556-48f6-4b8c-9fb6-921c12c9362f\"\\n                                          json=\\'{\"targeting\": {\"appname\": [\"googleamp\"], \"pos\": [\"rect_atf_01\"], \"hbg\":[\"US\"], \"hb_format\":[\"amp\"], \"spec\": \"the_point\" }, \"cepTopics\": {\"15HT\":\"cep_iabt\",\"15H4\":\"cep_iabt\",\"16BC\":\"cep_sent\",\"9C7\":\"cep_tags\",\"3T9\":\"cep_tags\",\"3TLB\":\"cep_tags\",\"2JP5\":\"cep_tags\",\"5NC\":\"cep_tags\",\"86P\":\"cep_tags\",\"3TLC\":\"cep_tags\",\"2PC9\":\"cep_tags\",\"DHX\":\"cep_tags\",\"BW0\":\"cep_tags\",\"3T6S\":\"cep_tags\",\"45Z\":\"cep_tags\",\"DBJ\":\"cep_tags\",\"2PCG\":\"cep_tags\",\"2PCF\":\"cep_tags\",\"3VT\":\"cep_tags\",\"BPP\":\"cep_tags\",\"5G8\":\"cep_tags\",\"7WN\":\"cep_tags\",\"DG2\":\"cep_tags\"} }\\'\\n                                          rtc-config=\\'{\"vendors\": {\"prebidappnexus\": {\"PLACEMENT_ID\": \"13994477\" }}, \"timeoutMillis\": \"750\"}\\'>\\n                                      </amp-ad>\\n                                  </div>\\n                                  \\n                                  \\n                                  <p>A quick check of history shows how strange that is.</p>\\n                                  \\n                                  \\n                                  \\n                                  \\n                                  \\n                                  <p>The peak of support for the impeachment and removal of then-President Bill Clinton in 1998 was 29% in CNN polling. That\\'s the <em>highest</em> that number ever went, despite the fact that the House Republican majority did vote to impeach late that year!</p>\\n                                  \\n                                  \\n                                  \\n                                  \\n                                  \\n                                  <p>Ditto impeachment sentiment for the two presidents between Clinton and Trump. In a 2006 CNN poll, 30% of the public wanted George W. Bush impeached and removed from office; in 2014, 33% said the same of Barack Obama. (Unlike Trump and Clinton, neither Bush nor Obama ever faced any sort of formal impeachment investigation or vote.)</p>\\n                                  \\n                                  \\n                                  <p>What those historical numbers tell us is that for at least the last two decades, there is roughly 30% of the country that is ready to impeach a president (usually of the party to which they do not belong) at all times. </p>\\n                                  \\n                                  \\n                                  \\n                                  \\n                                  \\n                                  <p>What makes the Trump number<em> so </em>remarkable, then, is that 20% more of the public is now convinced not only that he should be impeached but that he should be removed from office -- despite the fact that, unlike Clinton, Bush and Obama when those CNN polls were taken, Trump will face voters in a bid for a second term in less than a year\\'s time.</p>\\n                                  \\n                                  \\n                                  <p>Now, it is fair to say that Democrats -- if you gave them truth serum at the conclusion of last week\\'s public impeachment hearings -- believed they had hit a home run, and that polling would reflect that. That polling so far hasn\\'t changed all that much is worth noting.</p>\\n                                  \\n                                  \\n                                  <p>So that point is right -- for now. But it\\'s also worth noting that we are in the immediate aftermath of the hearings, and its findings may not have fully seeped into the public consciousness just yet. And more importantly, whether it\\'s 50% or 51% or 55%, it\\'s noteworthy that a majority of the public wants the President gone.</p>\\n                                  \\n                                  \\n                                  \\n                                  \\n                                  \\n                                  <p>Don\\'t get so close to the painting that you can\\'t see the full picture. And that full picture is this: 50% of the public believes Trump should be impeached and removed -- almost double the amount who have said that about any of his three most recent predecessors, including one who was actually impeached by the House.</p>\\n                                  \\n                                  \\n                                  <p>Don\\'t lose sight of those facts amid the narrow focus on whether the impeachment numbers have moved since the last poll. That 50% number is both astounding and ahistorical.</p>\\n                                  \\n                                  \\n                                  \\n                              <div class=\"l-standard-top\">\\n                                  <a href=\"https://www.cnn.com/2019/11/26/politics/trump-cnn-impeachment-poll/index.html\" class=\"button\">\\n                                      View on CNN\\n                                  </a>\\n                              </div>\\n                          </div>\\n                      </div>\\n              </div>\\n          </div>\\n          <div class=\"l-standard-top l-full-width\">\\n              <amp-embed\\n                    width=\"100\"\\n                    height=\"100\"\\n                    type=\"outbrain\"\\n                    layout=\"responsive\"\\n                    data-widgetids=\"AMP_1\"\\n                    data-testmode=\"false\"\\n                    data-htmlurl=\"https%3A%2F%2Fwww.cnn.com%2F2019%2F11%2F26%2Fpolitics%2Ftrump-cnn-impeachment-poll%2Findex.html\"\\n                    data-ampurl=\"https%3A%2F%2Famp.cnn.com%2Fcnn%2F2019%2F11%2F26%2Fpolitics%2Ftrump-cnn-impeachment-poll%2Findex.html\">\\n                    <div overflow tabindex=0 role=button aria-label=\"Outbrain Recommendations\">Outbrain</div>\\n              </amp-embed>\\n          </div>\\n          <div class=\"ad-container l-standard-top l-hide-on-desktop\">\\n            <amp-ad width=\"300\" height=\"150\"\\n                sizes=\"100vw\"\\n                type=\"yieldmo\"\\n                data-ymid=1357080996168236968>\\n            </amp-ad>\\n          </div>\\n          <amp-iframe\\n                  width=\"1\"\\n                  title=\"User Sync\"\\n                  height=\"1\"\\n                  sandbox=\"allow-scripts\"\\n                  frameborder=\"0\"\\n                  src=\"https://cdn.jsdelivr.net/npm/prebid-universal-creative@latest/dist/load-cookie.html\">\\n              <amp-img layout=\"fill\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==\" alt=\"placeholder\"></amp-img>\\n          </amp-iframe>\\n          <div class=\"l-full-width\">\\n              <div class=\"footer\">\\n                  <hr class=\"m-closing-accent\" />\\n                  <p class=\"footer-copyright m-font-small m-light-grey\">&copy; 2019 Cable News Network. Turner Broadcasting System, Inc. All Rights Reserved. </p>\\n                  <p class=\"footer-links m-font-small m-light-grey\">\\n                  \\t<a href=\"/terms\">Terms of Use </a> | <a href=\"/privacy\">Privacy Policy</a> | <a class=\"m-legal__links\" data-analytics=\"footer_adchoices\" href=\"http://preferences-mgr.truste.com/?pid=turnermedia01&aid=turnermedia01&type=turner_pop&affiliateId=pid=turnermedia01&aid=turnermedia01\">AdChoices</a>\\n                  </p>\\n              </div>\\n          </div>\\n      </div>\\n  </body>\\n</html>\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaPBUNXG-0LU"
      },
      "source": [
        "article1.parse()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAeyio6Ws1z9"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5nvn3df7jEW"
      },
      "source": [
        "article2.parse()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsLyBK537jR9"
      },
      "source": [
        "article3.parse()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LJDPJoy7jiO"
      },
      "source": [
        "article4.parse()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IupEzX24-8hH"
      },
      "source": [
        "Doc1 = article1.text\n",
        "Doc2 = article2.text\n",
        "Doc3 = article3.text\n",
        "Doc4 = article4.text\n",
        "\n",
        "\n",
        "article1.text\n",
        "Doc = (Doc1,Doc2,Doc3,Doc4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8UUp4dy7-7o",
        "outputId": "5fb5f2e3-43b9-4a78-89c8-8a70aa95aae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "article3.nlp()\n",
        "article3.keywords\n",
        "article3.summary\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7ciak5Cv4CS",
        "outputId": "c39a9155-9cf4-4b56-f776-1ed871e1271e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sentence_list1 = nltk.sent_tokenize(article1.text)\n",
        "sentence_list2 = nltk.sent_tokenize(article2.text)\n",
        "sentence_list3 = nltk.sent_tokenize(article3.text)\n",
        "sentence_list4 = nltk.sent_tokenize(article4.text)\n",
        "\n",
        "sentence_list=(sentence_list1,sentence_list2,sentence_list3,sentence_list4)\n",
        "\n",
        "out = [item for t in sentence_list for item in t]\n",
        "out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Even after last week’s extensive public hearings, the American public remains split on impeaching President Trump, with 50 percent in support of the process and 43 percent against it.',\n",
              " 'But some groups of Americans are a lot more supportive of impeachment than others.',\n",
              " 'In a CNN poll released Tuesday, a full 61 percent of women were in favor of impeaching Trump while 34 percent were against it.',\n",
              " 'Among men, by contrast, just 40 percent support impeachment and 53 percent oppose it.',\n",
              " 'The gender gap also shows up in Trump’s approval ratings: 52 percent of men approve of how the president is doing compared with 32 percent of women, according to the CNN poll.',\n",
              " 'One big factor at work in the gender divide is party identification.',\n",
              " 'Women are more likely than men to be Democrats, and “one of the strongest drivers of support for impeachment is partisanship,” Kelly Dittmar, an assistant professor of political science and scholar at the Center for American Women and Politics, told Vox.',\n",
              " 'In the CNN poll, 90 percent of Democrats supported impeachment compared with just 10 percent of Republicans.',\n",
              " 'But party may not be the only factor driving the gender gap.',\n",
              " 'Some argue that female voters, more so than men, are responding to the fact that Trump has been accused not just of a quid pro quo with Ukraine but also of sexually assaulting, harassing, or otherwise violating more than 20 women.',\n",
              " 'Those allegations aren’t part of the impeachment inquiry, but Trump is facing two ongoing lawsuits in connection with them, and they’re likely to remain in the public eye through 2020.',\n",
              " 'It’s not yet clear from polling how much women’s dislike of Trump goes beyond their party identification or how much has to do with the allegations against him.',\n",
              " 'But as the next election approaches — with female voters poised to play a deciding role — the answer to those questions will matter.',\n",
              " 'There’s a 20-point gender gap in support for impeachment\\n\\nThe CNN poll, conducted for the network by research firm SSRS between November 21 and 24 with a sample size of 1,007 Americans, found that support for impeachment among Americans in general has not changed since October, before the House held public hearings on the subject.',\n",
              " 'Fifty percent of Americans supported impeachment in the November poll, the same share who supported it in a similar CNN poll conducted from October 17-20.',\n",
              " 'Among women, however, the numbers are much higher and growing, with 61 percent now supporting impeachment compared with 56 percent in October and 51 percent in May.',\n",
              " 'By contrast, a majority of men — 53 percent — still oppose impeachment.',\n",
              " 'The simplest explanation for the gender gap is party, according to Dittmar: “What we know drives gender differences in politics is also gender differences in party identification.” According to a 2018 study by the Pew Research Center, 56 percent of women are Democrats or lean Democratic, compared with 44 percent of men.',\n",
              " 'But party may not be the whole story.',\n",
              " 'Responding to the CNN poll, former prosecutor and NBC legal analyst Mimi Rocah tweeted, “When a serial abuser & criminal sits unchecked in the White House, women see the threat.”\\n\\nShe was presumably referring to the more than 20 sexual misconduct allegations against the president.',\n",
              " 'Trump has denied the allegations against him and said the women who came forward were liars.',\n",
              " 'Two of those women, restaurant owner Summer Zervos and author E. Jean Carroll, have filed defamation suits against Trump.',\n",
              " 'The Zervos suit is currently in discovery, with phone records recently released showing that Trump called Zervos on the day she says he sexually assaulted her.',\n",
              " 'A number of sexual misconduct allegations came out against Trump after the Access Hollywood tape was released in October 2016, showing Trump bragging about his ability to grab women “by the pussy.” In polling at the time, “women were particularly responsive” to the allegations, Dittmar said, and some speculated that Republican women might abandon Trump over the news.',\n",
              " 'A prominent Evangelical speaker, Beth Moore, even came out against Trump in the wake of the tape, as Lyz Lenz reported at Marie Claire at the time.',\n",
              " 'But then came James Comey’s letter regarding Hillary Clinton’s emails, and Trump, obviously, ended up winning the election — with, famously, 53 percent of white female voters supporting him.',\n",
              " 'For many of those voters, party was likely just as important than gender.',\n",
              " 'And in more recent polling, Republican women have continued to support Trump at about the same level as Republican men: 85 percent of Republican women approve of how the president is doing compared with 86 percent of Republican men, according to recent data from Morning Consult.',\n",
              " 'But those numbers don’t necessarily tell the whole story.',\n",
              " 'They don’t capture, for instance, women who may have left the Republican Party over the nomination and presidency of Trump.',\n",
              " '“Are there women who don’t identify as Republican in part because of what’s been happening” in the party and in the White House, Dittmar asks.',\n",
              " 'That’s “part of the gender story that we just might not be capturing.”\\n\\nThe question is important in part because Trump’s demeaning comments about women didn’t end when he took office.',\n",
              " 'Since then, he’s mocked Christine Blasey Ford for her testimony that Brett Kavanaugh, now a Supreme Court Justice, sexually assaulted her when the two were in high school.',\n",
              " 'More recently, after Carroll said that Trump had sexually assaulted her in the 1990s, the president responded that she was “not my type” and claimed never to have met her — even though her New York magazine story about the encounter included a photo of the two together.',\n",
              " 'Comments like this don’t have anything to do with the current Ukraine inquiry.',\n",
              " 'But as Megan Garber points out at the Atlantic, the sexual misconduct allegations hang over that inquiry, raising the question of why they haven’t merited the same official response.',\n",
              " 'There’s no reason, of course, why male voters can’t care about sexual misconduct allegations, too.',\n",
              " 'In fact, there’s evidence that they do, with 70 percent of Democratic men saying in a recent poll that the Kavanaugh hearings made them think about men having more power in government.',\n",
              " 'But female voters may react even more strongly: 83 percent of Democratic women in the poll said the Kavanaugh episode made them think about gender and power in government.',\n",
              " 'And so it’s entirely possible that women, perhaps in both parties, are looking at the impeachment hearings and thinking about the many women who have come forward over the years to say Trump violated them, and the fact that he still holds the highest office in our country — for now.',\n",
              " 'The gender gap could be important information for 2020\\n\\nIn today’s political environment, polls about impeachment are never just about impeachment.',\n",
              " 'They’re also about how Trump, the Republicans, and the Democrats will fare in 2020.',\n",
              " 'And the latest numbers on the gender gap offer a couple of clues.',\n",
              " 'For one, Dittmar said, they send a signal to Democrats that women in general are squarely behind impeachment.',\n",
              " 'That’s especially important to future Democratic candidates because female voters outnumber men and are more likely to turn out, Dittmar said.',\n",
              " 'Their votes are particularly important to Democrats.',\n",
              " '“If you’re a Democrat, women are effectively your base,” Dittmar said — especially black women, who voted for Democrats in overwhelming majorities in 2016 and 2018.',\n",
              " 'So for Democrats, the poll numbers are a sign that among one key voting bloc, at least, there’s little political cost to proceeding with impeachment.',\n",
              " 'More broadly, women’s support for impeachment is yet more evidence that female voters strongly dislike Trump, and that this could drive turnout in 2020.',\n",
              " 'For Democratic women, Dittmar said, “this is probably going to continue to mobilize them to come out and play a significant role” in that election.',\n",
              " 'The big remaining question, though, is what Trump’s presidency has meant and will mean for Republican women — or women who used to be Republican but now “feel like they don’t have a home,” in Dittmar’s words, after the 2016 election.',\n",
              " 'Will dislike for Trump motivate them to turn out in 2020?',\n",
              " 'And will they vote for the Democrat, whoever that may be?',\n",
              " 'The polling on impeachment can’t answer these questions.',\n",
              " 'But if Democrats want to win in 2020 — especially in states like Pennsylvania, Michigan, and Wisconsin, where the votes of non-college-educated white women were enough to hand victory to Trump — they probably need to be asking them.',\n",
              " '(CNN) A new CNN poll shows that half the country believes that President Donald Trump should be not only impeached by the House, but also removed from office by the Senate.',\n",
              " 'That result is being spun in some corners of the internet as great news for Trump, because that 50% number is unchanged from a CNN poll in mid-October, the conclusion being that the last 10 days of public impeachment hearings have not convinced more of the public that the President needs to go.',\n",
              " 'Except that we are missing the forest for the trees here: A majority of the country believes the current President of the United States should be impeached and removed from office!',\n",
              " 'A quick check of history shows how strange that is.',\n",
              " 'The peak of support for the impeachment and removal of then-President Bill Clinton in 1998 was 29% in CNN polling.',\n",
              " \"That's the highest that number ever went, despite the fact that the House Republican majority did vote to impeach late that year!\",\n",
              " 'Ditto impeachment sentiment for the two presidents between Clinton and Trump.',\n",
              " 'In a 2006 CNN poll, 30% of the public wanted George W. Bush impeached and removed from office; in 2014, 33% said the same of Barack Obama.',\n",
              " '(Unlike Trump and Clinton, neither Bush nor Obama ever faced any sort of formal impeachment investigation or vote.)',\n",
              " 'What those historical numbers tell us is that for at least the last two decades, there is roughly 30% of the country that is ready to impeach a president (usually of the party to which they do not belong) at all times.',\n",
              " \"What makes the Trump number so remarkable, then, is that 20% more of the public is now convinced not only that he should be impeached but that he should be removed from office -- despite the fact that, unlike Clinton, Bush and Obama when those CNN polls were taken, Trump will face voters in a bid for a second term in less than a year's time.\",\n",
              " \"Now, it is fair to say that Democrats -- if you gave them truth serum at the conclusion of last week's public impeachment hearings -- believed they had hit a home run, and that polling would reflect that.\",\n",
              " \"That polling so far hasn't changed all that much is worth noting.\",\n",
              " 'So that point is right -- for now.',\n",
              " \"But it's also worth noting that we are in the immediate aftermath of the hearings, and its findings may not have fully seeped into the public consciousness just yet.\",\n",
              " \"And more importantly, whether it's 50% or 51% or 55%, it's noteworthy that a majority of the public wants the President gone.\",\n",
              " \"Don't get so close to the painting that you can't see the full picture.\",\n",
              " 'And that full picture is this: 50% of the public believes Trump should be impeached and removed -- almost double the amount who have said that about any of his three most recent predecessors, including one who was actually impeached by the House.',\n",
              " \"Don't lose sight of those facts amid the narrow focus on whether the impeachment numbers have moved since the last poll.\",\n",
              " 'That 50% number is both astounding and ahistorical.',\n",
              " \"William Cummings | USA TODAY\\n\\nHannah Gaber, USA TODAY\\n\\nSupport for President Donald Trump's impeachment remains at about 50% despite two weeks of testimony in public hearings that Democrats felt strongly bolstered their case, according to a CNN poll released Tuesday.\",\n",
              " 'Half of Americans said Trump should be impeached and removed from office, while 43% said he should not, exactly the result CNN got in a poll conducted from Oct. 17-20, before the hearings began.',\n",
              " 'Of those who support impeachment, 91% said they \"strongly\" felt that way, a one percentage point increase from the month before.',\n",
              " 'Among those who oppose impeachment, the number who strongly felt that way climbed from 86% to 89%.',\n",
              " 'As has been the case with virtually every poll on impeachment, the numbers were clearly divided by party affiliation, race and gender.',\n",
              " 'Among Democrats, 90% favored impeachment while 87% of Republicans were opposed.',\n",
              " 'Independents were split, 46% to 47%.',\n",
              " 'Sixty-one percent of women and 40% of men said Trump should be removed from office, while 34% of women and 53% of men were opposed.',\n",
              " 'Among non-whites, 65% support impeachment while 51% of whites are opposed.',\n",
              " '‘Presidents are not kings’: Judge says ex-White House counsel Donald McGahn must testify before Congress\\n\\nJust the FAQs, USA TODAY\\n\\nThe demographic group most opposed to removing Trump was non-college educated whites at 56%.',\n",
              " 'More than three-quarters of Americans said they have been following the impeachment proceedings at least \"somewhat closely\" while 23% said they were not following too closely or not closely at all.',\n",
              " 'Trump is accused of using the power of his office to pressure Ukraine into opening investigations that stood to benefit him politically: one to look into an unsubstantiated theory that Ukraine, and not Russia, was behind the theft of emails from the Democratic National Committee and Clinton campaign in 2016, the other into an energy company whose board includes the son of former Vice President Joe Biden.',\n",
              " 'Trump has defended his calls for the investigations as efforts to combat corruption in a country receiving large amounts of U.S. assistance and has denied any political motivation.',\n",
              " 'But 56% of Americans told CNN\\'s pollsters that they believed Trump acted \"more to benefit himself politically\" while 36% said they thought he was more interested in fighting corruption in Ukraine.',\n",
              " 'And 53% said he had used the power of the presidency for political gain, while 42% said he \"did not use the presidency improperly.\"',\n",
              " \"The poll found Trump's job approval rating at 42% and his job disapproval at 54%, within the range its polls have found for most of his presidency.\",\n",
              " 'Fifty-five percent approved of his handling of the economy, his highest mark in a CNN poll since April.',\n",
              " 'The poll was conducted from Nov. 21-24 with a margin of error of plus or minus 3.7%.',\n",
              " \"View | 88 Photos\\n\\nDonald Trump's impeachment inquiry related to Ukraine in pictures\",\n",
              " 'NEW YORKNEW YORK (Reuters) - Public support for impeaching President Donald Trump has tracked steadily higher over the past few weeks while a U.S. House of Representatives committee held a series of televised impeachment hearings, according to a Reuters/Ipsos opinion poll released on Tuesday.',\n",
              " 'The latest poll, conducted on Monday and Tuesday, found that 47% of adults in the United States felt Trump \"should be impeached,\" while 40% said he should not.',\n",
              " 'The result, combined with Reuters/Ipsos polling over the past several weeks, showed that the number of Americans who want to impeach the president increasingly outnumbers those who do not.',\n",
              " 'ADVERTISEMENT\\n\\nJust before the hearings started on Nov. 13, the Reuters/Ipsos poll found that \"net support\" for impeachment, which is the difference between the number who support impeachment and the number who oppose, was 3 percentage points.',\n",
              " 'That increased to 4 points after the first week of hearings, and then to 5 points as the second week of hearings started.',\n",
              " 'The latest poll shows that net support for impeachment is now at 7 points.',\n",
              " 'The inquiry centers on a July 25 phone call in which Trump asked Ukrainian President Volodymyr Zelenskiy to investigate Democratic presidential contender Joe Biden and his son Hunter Biden as well as a discredited conspiracy theory promoted by Trump that Ukraine, not Russia, interfered in the 2016 U.S. presidential election.',\n",
              " 'Hunter Biden had worked for a Ukrainian energy company.',\n",
              " 'Democrats have accused Trump of abusing his power by withholding $391 million in security aid to put pressure on a vulnerable U.S. ally to interfere in an American election by digging up dirt on his domestic political opponents.',\n",
              " \"If articles of impeachment are approved by the Democratic-controlled House, the Senate, controlled by Trump's fellow Republicans, would hold a trial on whether to convict Trump and remove him from office.\",\n",
              " 'Republicans have shown little inclination toward removing Trump, who is seeking re-election in 2020.',\n",
              " 'Trump denies wrongdoing and has dismissed the inquiry as a hoax or effort by Democrats to overturn the result of the 2016 election.',\n",
              " 'ADVERTISEMENT\\n\\nPARTY LINES\\n\\nPublic opinion about impeachment remains split along party lines, with about eight in 10 Democrats supportive of impeaching Trump, and eight in 10 Republicans opposed.',\n",
              " 'FILE PHOTO: Fiona Hill, former National Security Council Russia expert, center right, and David Holmes, counselor for political affairs at the U.S. Embassy in Ukraine, center left, testify during a House Intelligence Committee impeachment inquiry hearing in Washington, D.C., U.S., on Thursday, Nov. 21, 2019.',\n",
              " \"Andrew Harrer/Pool via Reuters/File Photo FILE PHOTO: U.S. President Donald Trump speaks during a signing ceremony for the ''Women's Suffrage Centennial Commemorative Coin Act'' in the Oval Office of the White House in Washington, U.S., November 25, 2019.\",\n",
              " 'Reuters/Loren Elliott\\n\\nThe Reuters/Ipsos poll showed that seven in 10 Republicans believed the House inquiry had not been conducted fairly, and most Republicans opposed impeachment for anything short of outright lawbreaking by the president.',\n",
              " 'Four in 10 Republicans agreed that a president who uses his powers for financial gain should face an impeachment inquiry, while three in 10 said it would be justified for a president who obstructs justice or harms U.S. interests abroad.',\n",
              " 'Only two in 10 said an inquiry would be justified for a president who uses his powers for unfair political advantage over an opponent, as Trump is accused of doing.',\n",
              " 'The Reuters/Ipsos poll was conducted online, in English, throughout the United States.',\n",
              " 'It gathered responses from 1,118 adults, including 528 Democrats, 394 Republicans and 111 independents.',\n",
              " 'It has a credibility interval, a measure of precision, of 3 percentage points.',\n",
              " 'ADVERTISEMENT']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQiPV618wZAf"
      },
      "source": [
        "for art in Doc:\n",
        "\n",
        "\n",
        "\n",
        "  stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "\n",
        "\n",
        "  word_frequencies = {}\n",
        "  for word in nltk.word_tokenize(Doc3):\n",
        "      if word not in stopwords:\n",
        "          if word not in word_frequencies.keys():\n",
        "              word_frequencies[word] = 1\n",
        "          else:\n",
        "              word_frequencies[word] += 1\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJRkSTJewswq"
      },
      "source": [
        "maximum_frequncy = max(word_frequencies.values())\n",
        "\n",
        "for word in word_frequencies.keys():\n",
        "    word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abqGN67-wyLA"
      },
      "source": [
        "sentence_scores = {}\n",
        "#change out\n",
        "for sent in sentence_list1:\n",
        "    for word in nltk.word_tokenize(sent.lower()):\n",
        "        if word in word_frequencies.keys():\n",
        "            if len(sent.split(' ')) < 30:\n",
        "                if sent not in sentence_scores.keys():\n",
        "                    sentence_scores[sent] = word_frequencies[word]\n",
        "                else:\n",
        "                    sentence_scores[sent] += word_frequencies[word]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBAtEy9Xw3K6",
        "outputId": "c5e07a69-b2b5-4b56-f7da-058ee16dbef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "import heapq\n",
        "summary_sentences = heapq.nlargest(40, sentence_scores, key=sentence_scores.get)\n",
        "\n",
        "summary = ' '.join(summary_sentences)\n",
        "print(summary)\n",
        "\n",
        "article = summary\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "But then came James Comey’s letter regarding Hillary Clinton’s emails, and Trump, obviously, ended up winning the election — with, famously, 53 percent of white female voters supporting him. So for Democrats, the poll numbers are a sign that among one key voting bloc, at least, there’s little political cost to proceeding with impeachment. Among women, however, the numbers are much higher and growing, with 61 percent now supporting impeachment compared with 56 percent in October and 51 percent in May. “If you’re a Democrat, women are effectively your base,” Dittmar said — especially black women, who voted for Democrats in overwhelming majorities in 2016 and 2018. Since then, he’s mocked Christine Blasey Ford for her testimony that Brett Kavanaugh, now a Supreme Court Justice, sexually assaulted her when the two were in high school. There’s no reason, of course, why male voters can’t care about sexual misconduct allegations, too. For one, Dittmar said, they send a signal to Democrats that women in general are squarely behind impeachment. A prominent Evangelical speaker, Beth Moore, even came out against Trump in the wake of the tape, as Lyz Lenz reported at Marie Claire at the time. Among men, by contrast, just 40 percent support impeachment and 53 percent oppose it. More broadly, women’s support for impeachment is yet more evidence that female voters strongly dislike Trump, and that this could drive turnout in 2020. Even after last week’s extensive public hearings, the American public remains split on impeaching President Trump, with 50 percent in support of the process and 43 percent against it. For Democratic women, Dittmar said, “this is probably going to continue to mobilize them to come out and play a significant role” in that election. They don’t capture, for instance, women who may have left the Republican Party over the nomination and presidency of Trump. Fifty percent of Americans supported impeachment in the November poll, the same share who supported it in a similar CNN poll conducted from October 17-20. Two of those women, restaurant owner Summer Zervos and author E. Jean Carroll, have filed defamation suits against Trump. But as Megan Garber points out at the Atlantic, the sexual misconduct allegations hang over that inquiry, raising the question of why they haven’t merited the same official response. They’re also about how Trump, the Republicans, and the Democrats will fare in 2020. The gender gap could be important information for 2020\n",
            "\n",
            "In today’s political environment, polls about impeachment are never just about impeachment. In the CNN poll, 90 percent of Democrats supported impeachment compared with just 10 percent of Republicans. By contrast, a majority of men — 53 percent — still oppose impeachment. In a CNN poll released Tuesday, a full 61 percent of women were in favor of impeaching Trump while 34 percent were against it. That’s especially important to future Democratic candidates because female voters outnumber men and are more likely to turn out, Dittmar said. But female voters may react even more strongly: 83 percent of Democratic women in the poll said the Kavanaugh episode made them think about gender and power in government. “Are there women who don’t identify as Republican in part because of what’s been happening” in the party and in the White House, Dittmar asks. The Zervos suit is currently in discovery, with phone records recently released showing that Trump called Zervos on the day she says he sexually assaulted her. For many of those voters, party was likely just as important than gender. Trump has denied the allegations against him and said the women who came forward were liars. The polling on impeachment can’t answer these questions. But some groups of Americans are a lot more supportive of impeachment than others. It’s not yet clear from polling how much women’s dislike of Trump goes beyond their party identification or how much has to do with the allegations against him. One big factor at work in the gender divide is party identification. And will they vote for the Democrat, whoever that may be? But party may not be the only factor driving the gender gap. But those numbers don’t necessarily tell the whole story. Comments like this don’t have anything to do with the current Ukraine inquiry. And the latest numbers on the gender gap offer a couple of clues. But party may not be the whole story. But as the next election approaches — with female voters poised to play a deciding role — the answer to those questions will matter. Their votes are particularly important to Democrats.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUpuYayPW7BA"
      },
      "source": [
        "pip install -update _version\n",
        "from textteaser import TextTeaser\n",
        "tt = TextTeaser()\n",
        "tt.summarize(title, Doc2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdnCO-7s8Rln"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "# tokenization\n",
        "X_list = word_tokenize(Doc1)\n",
        "Y_list = word_tokenize(Doc4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS0Nh9GX-bT_"
      },
      "source": [
        "# sw contains the list of stopwords\n",
        "sw = stopwords.words('english')\n",
        "l1 =[];l2 =[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkpkpvfH-n06"
      },
      "source": [
        "# remove stop words from string\n",
        "X_set = {w for w in X_list if not w in sw}\n",
        "Y_set = {w for w in Y_list if not w in sw}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dmt8_8MW-pTS"
      },
      "source": [
        "# form a set containing keywords of both strings\n",
        "rvector = X_set.union(Y_set)\n",
        "for w in rvector:\n",
        "    if w in X_set: l1.append(1) # create a vector\n",
        "    else: l1.append(0)\n",
        "    if w in Y_set: l2.append(1)\n",
        "    else: l2.append(0)\n",
        "c = 0\n",
        "\n",
        "# cosine formula\n",
        "for i in range(len(rvector)):\n",
        "        c+= l1[i]*l2[i]\n",
        "cosine = c / float((sum(l1)*sum(l2))**0.5)\n",
        "print(\"similarity between article 3,4: \", cosine)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcwzUzQn5ud4"
      },
      "source": [
        "authorname = []\n",
        "title = []\n",
        "thearticle = []\n",
        "\n",
        "# store the text for each article\n",
        "articletext = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "aname = article.authors\n",
        "# get article title\n",
        "\n",
        "thetitle = article.title\n",
        "\n",
        "# get text\n",
        "articletext = article.text\n",
        "\n",
        "\n",
        "# combine all paragraphs into an article\n",
        "thearticle.append(articletext)\n",
        "authorname.append(aname)\n",
        "title.append(thetitle)\n",
        "myarticle = [' '.join(article) for article in thearticle]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRsm5Bz-8hO7"
      },
      "source": [
        "\n",
        "articletext\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvM9lriq6d-V"
      },
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "# save article data to file\n",
        "data = {'Title':article.title,\n",
        "        'Author':article.authors,\n",
        "        'PageLink':url,\n",
        "        'Article':article.text,\n",
        "        'Date':article.publish_date,\n",
        "        'Summary':article.summary,\n",
        "        'Keywords':listToStr}\n",
        "\n",
        "oldnews = pd.read_excel('/content/news.xls')\n",
        "news = pd.DataFrame(data=data)\n",
        "cols = ['Title', 'Author', 'PageLink', 'Article', 'Date', 'Summary','Keywords']\n",
        "news = news[cols]\n",
        "afronews = oldnews.append(news)\n",
        "afronews.drop_duplicates(subset='Title', keep='last', inplace=True)\n",
        "afronews.reset_index(inplace=True)\n",
        "afronews.drop(labels='index', axis=1, inplace=True)\n",
        "filename = '/content/news.xls'\n",
        "wks_name = 'Data'\n",
        "writer = pd.ExcelWriter(filename)\n",
        "afronews.to_excel(writer, wks_name, index=False)\n",
        "writer.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2x9vimyZpJz"
      },
      "source": [
        "#!python -m spacy link en_core_web_sm en\n",
        "!python -m spacy download en_core_web_lg\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxL50KLHxQrs"
      },
      "source": [
        "!python -m spacy link en_core_web_lg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzeTImVeZ44Y"
      },
      "source": [
        "pip install textacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOetWV93Z8qC"
      },
      "source": [
        "!python -m textacy download depeche_mood"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0zNn7dlaCb_"
      },
      "source": [
        "!python -m textacy --help"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLOaSkWvaiXs"
      },
      "source": [
        "#doc = textacy.make_spacy_doc(text)\n",
        "from pathlib import Path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x_7ddXuJHMm"
      },
      "source": [
        "#!python -m spacy download en_core_web_lg\n",
        "#!pip install -U spacy download en_core_web_sm\n",
        "import spacy\n",
        "import textacy\n",
        "text = Doc2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import sys\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVnSmNPZbMJs"
      },
      "source": [
        "\n",
        "#import neuralcoref\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "#neuralcoref.add_to_pipe(nlp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXb9fS19bMC7"
      },
      "source": [
        "\n",
        "doc = nlp1(article3.summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF7sg7egxIlQ"
      },
      "source": [
        "nlp1 = spacy.load('en_core_web_lg')\n",
        "doc = nlp1(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwvYeyCVdbyQ",
        "outputId": "d85b4227-7a45-43c5-efc1-5a87a5e837b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "print(doc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "William Cummings | USA TODAYHannah Gaber, USA TODAYSupport for President Donald Trump's impeachment remains at about 50% despite two weeks of testimony in public hearings that Democrats felt strongly bolstered their case, according to a CNN poll released Tuesday.\n",
            "Of those who support impeachment, 91% said they \"strongly\" felt that way, a one percentage point increase from the month before.\n",
            "Among those who oppose impeachment, the number who strongly felt that way climbed from 86% to 89%.\n",
            "As has been the case with virtually every poll on impeachment, the numbers were clearly divided by party affiliation, race and gender.\n",
            "View | 88 PhotosDonald Trump's impeachment inquiry related to Ukraine in pictures\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4DEs0fMeDtZ"
      },
      "source": [
        "print(\"Named Entities\")\n",
        "for entity in doc.ents:\n",
        "    print(f\" - {entity.text} ({entity.label_})\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQDf8rLdeD5J"
      },
      "source": [
        "svos = textacy.extract.subject_verb_object_triples(doc)\n",
        "\n",
        "# Print the results\n",
        "print(\"Subject, verb, object tuples:\")\n",
        "\n",
        "for svo in svos:\n",
        "    subject, verb, object = svo\n",
        "    print(f\" - {svo}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVFxP_W3RNv8"
      },
      "source": [
        "import spacy\n",
        "import textacy.extract"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u85stowVfoC"
      },
      "source": [
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LnAailOROGi"
      },
      "source": [
        "document = nlp(text)\n",
        "document"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWArOXrjW85C"
      },
      "source": [
        "statements = textacy.extract.semistructured_statements(doc, \"President\")\n",
        "\n",
        "print(\"**** Information on Trump ****\")\n",
        "count = 1\n",
        "for statement in statements:\n",
        "    subject, verb, fact = statement\n",
        "    print(str(count) + \" - Statement: \", statement,  cue=token.lemma_ , ignore_entity_case=True)\n",
        "    print(str(count) + \" - Fact: \", fact)\n",
        "    count += 1\n",
        "for entity in doc.ents:\n",
        "\n",
        "\n",
        "  print(f\"{entity.text} ({entity.label_})\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE1TwULMm0Dq"
      },
      "source": [
        "text = Path(\"/content/trump.txt\").read_text()\n",
        "text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd-I1m9Trqb5"
      },
      "source": [
        "# Parse the document with spaCy\n",
        "doc = nlp(text)\n",
        "doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_HI55LvryIS"
      },
      "source": [
        "statements = textacy.extract.semistructured_statements(doc, \"Democrats\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mupZ4JKCr9Rm"
      },
      "source": [
        "print(\"Here are the things I know about Trump:\\n\")\n",
        "\n",
        "for statement in statements:\n",
        "    subject, verb, fact = statement\n",
        "    print(f\"- {fact}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90EccFC-vFKz"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zghKMO44r73e"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwE7bBGReEJf"
      },
      "source": [
        "# Print the results\n",
        "print(\"Here are the facts on Donald Trump :\")\n",
        "for token in doc:\n",
        "\n",
        "  verb1 = token.lemma_\n",
        "\n",
        "  #if token.pos_ == 'VERB':\n",
        "\n",
        "\n",
        "\n",
        "    # Extract semi-structured statements\n",
        "  statements = textacy.extract.semistructured_statements(doc, \"Trump\", cue=token.lemma_, ignore_entity_case=True)\n",
        "\n",
        "  for statement in statements:\n",
        "\n",
        "\n",
        "      #if token.pos_ == 'VERB':\n",
        "    entity, verb, fact = statement\n",
        "    print(f\" - \", verb1, \" \" + token.text + \" \" + str(fact))\n",
        "        #qg.generate_closed_question(doc, \"impeachment proceeding\", token)\n",
        "        #print(f\" - \" + str(fact))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZYyQeWmU9iM"
      },
      "source": [
        "pip install textteaser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4UZAmGoLzlp"
      },
      "source": [
        "from gensim.test.utils import common_dictionary, common_corpus\n",
        "from gensim.models import LsiModel\n",
        "model = LsiModel(common_corpus, id2word=common_dictionary)\n",
        "vectorized_corpus = model[common_corpus]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqATYZaGTivu"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QkBqaqWyUH5"
      },
      "source": [
        "list(textacy.extract.semistructured_statements(doc, \"Trump\", cue=token.lemma_, ignore_entity_case=True))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJmjkibLPkcW"
      },
      "source": [
        "statements = textacy.extract.semistructured_statements(Doc2,\"Trump\")\n",
        "\n",
        "print(\"This text is about: \")\n",
        "for statement in statements:\n",
        "    subject,verb,point = statement\n",
        "    print(f':{point}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93NMY5-cNeqw"
      },
      "source": [
        "nlp = spacy.load('en_core_web_lg')\n",
        "from pathlib import Path\n",
        "\n",
        "text = Path(\"/content/trump.txt\").read_text()\n",
        "\n",
        "doc = textacy.make_spacy_doc(text,lang='en_core_web_sm')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNUBYkddbLbF"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vzy2_OGQ1zS"
      },
      "source": [
        "statements = textacy.extract.semistructured_statements(doc, \"Impeachment\")\n",
        "statements"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHYzPukrQ2Dh"
      },
      "source": [
        "\n",
        "\n",
        "for statement in statements:\n",
        "    subject,verb,fact=statement\n",
        "    print(fact)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CzdckVdQ2Oc"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHoPJFQTLv5O"
      },
      "source": [
        "pip install textacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF-SJqy3QWCK"
      },
      "source": [
        "pip install -U spacy==2.1.8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFmAXWs-s414",
        "outputId": "3ae342dc-7c76-433d-d300-1a8b09a0a2e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn import preprocessing, svm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import datetime\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "import requests\n",
        "from pandas_datareader import data\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from yahoofinancials import YahooFinancials\n",
        "import datetime\n",
        "import sys\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#from datetime import datetime\n",
        "#from datetime import timedelta\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter('ignore')\n",
        "sns.set()\n",
        "tf.compat.v1.random.set_random_seed(1234)\n",
        "# To grab stock data\n",
        "import yfinance as fyf\n",
        "from pandas_datareader import data as pdr\n",
        "fyf.pdr_override()\n",
        "stocks = [\"AAPL\"] # If you want to grab multiple stocks add more labels to this list\n",
        "\n",
        "# Set start and end dates\n",
        "start = datetime.datetime(1995, 1, 1)\n",
        "end   = datetime.datetime.now()\n",
        "\n",
        "# Grab data\n",
        "df = pdr.get_data_yahoo(stocks, start = start, end = end)\n",
        "print(df.head())\n",
        "\n",
        "minmax = MinMaxScaler().fit(df.iloc[:, 4:5].astype('float32')) # Close index\n",
        "df_log = minmax.transform(df.iloc[:, 4:5].astype('float32')) # Close index\n",
        "df_log = pd.DataFrame(df_log)\n",
        "print(df_log.head())\n",
        "\n",
        "simulation_size = 6\n",
        "num_layers = 1\n",
        "size_layer = 128\n",
        "timestamp = 5\n",
        "epoch = 300\n",
        "dropout_rate = 0.8\n",
        "test_size = 30\n",
        "learning_rate = 0.01\n",
        "\n",
        "df_train = df_log\n",
        "print(df.shape, df_train.shape)\n",
        "\n",
        "\n",
        "class Model:\n",
        "    def __init__(\n",
        "            self,\n",
        "            learning_rate,\n",
        "            num_layers,\n",
        "            size,\n",
        "            size_layer,\n",
        "            output_size,\n",
        "            forget_bias=0.1,\n",
        "    ):\n",
        "        def lstm_cell(size_layer):\n",
        "            return tf.keras.layers.LSTMCell(size_layer, state_is_tuple=False)\n",
        "\n",
        "        rnn_cells = tf.keras.layers.StackedRNNCells(\n",
        "            [lstm_cell(size_layer) for _ in range(num_layers)],\n",
        "            state_is_tuple=False,\n",
        "        )\n",
        "        self.X = tf.placeholder(tf.float32, (None, None, size))\n",
        "        self.Y = tf.placeholder(tf.float32, (None, output_size))\n",
        "        drop = tf.contrib.rnn.DropoutWrapper(\n",
        "            rnn_cells, output_keep_prob=forget_bias\n",
        "        )\n",
        "        self.hidden_layer = tf.placeholder(\n",
        "            tf.float32, (None, num_layers * 2 * size_layer)\n",
        "        )\n",
        "        self.outputs, self.last_state = tf.nn.dynamic_rnn(\n",
        "            drop, self.X, initial_state=self.hidden_layer, dtype=tf.float32\n",
        "        )\n",
        "        self.logits = tf.layers.dense(self.outputs[-1], output_size)\n",
        "        self.cost = tf.reduce_mean(tf.square(self.Y - self.logits))\n",
        "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(\n",
        "            self.cost\n",
        "        )\n",
        "\n",
        "\n",
        "def calculate_accuracy(real, predict):\n",
        "    real = np.array(real) + 1\n",
        "    predict = np.array(predict) + 1\n",
        "    percentage = 1 - np.sqrt(np.mean(np.square((real - predict) / real)))\n",
        "    return percentage * 100\n",
        "\n",
        "\n",
        "def anchor(signal, weight):\n",
        "    buffer = []\n",
        "    last = signal[0]\n",
        "    for i in signal:\n",
        "        smoothed_val = last * weight + (1 - weight) * i\n",
        "        buffer.append(smoothed_val)\n",
        "        last = smoothed_val\n",
        "    return buffer\n",
        "\n",
        "\n",
        "def forecast():\n",
        "    tf.compat.v1.reset_default_graph()\n",
        "    modelnn = Model(learning_rate, num_layers, df_log.shape[1], size_layer, df_log.shape[1], dropout_rate)\n",
        "    sess = tf.InteractiveSession()\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    date_ori = pd.to_datetime(df.iloc[:, 0]).tolist()\n",
        "\n",
        "    pbar = tqdm(range(epoch), desc='train loop')\n",
        "    for i in pbar:\n",
        "        init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
        "        total_loss, total_acc = [], []\n",
        "        for k in range(0, df_train.shape[0] - 1, timestamp):\n",
        "            index = min(k + timestamp, df_train.shape[0] - 1)\n",
        "            batch_x = np.expand_dims(\n",
        "                df_train.iloc[k: index, :].values, axis=0\n",
        "            )\n",
        "            batch_y = df_train.iloc[k + 1: index + 1, :].values\n",
        "            logits, last_state, _, loss = sess.run(\n",
        "                [modelnn.logits, modelnn.last_state, modelnn.optimizer, modelnn.cost],\n",
        "                feed_dict={\n",
        "                    modelnn.X: batch_x,\n",
        "                    modelnn.Y: batch_y,\n",
        "                    modelnn.hidden_layer: init_value,\n",
        "                },\n",
        "            )\n",
        "            init_value = last_state\n",
        "            total_loss.append(loss)\n",
        "            total_acc.append(calculate_accuracy(batch_y[:, 0], logits[:, 0]))\n",
        "        pbar.set_postfix(cost=np.mean(total_loss), acc=np.mean(total_acc))\n",
        "\n",
        "    future_day = test_size\n",
        "\n",
        "    output_predict = np.zeros((df_train.shape[0] + future_day, df_train.shape[1]))\n",
        "    output_predict[0] = df_train.iloc[0]\n",
        "    upper_b = (df_train.shape[0] // timestamp) * timestamp\n",
        "    init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
        "\n",
        "    for k in range(0, (df_train.shape[0] // timestamp) * timestamp, timestamp):\n",
        "        out_logits, last_state = sess.run(\n",
        "            [modelnn.logits, modelnn.last_state],\n",
        "            feed_dict={\n",
        "                modelnn.X: np.expand_dims(\n",
        "                    df_train.iloc[k: k + timestamp], axis=0\n",
        "                ),\n",
        "                modelnn.hidden_layer: init_value,\n",
        "            },\n",
        "        )\n",
        "        init_value = last_state\n",
        "        output_predict[k + 1: k + timestamp + 1] = out_logits\n",
        "\n",
        "    if upper_b != df_train.shape[0]:\n",
        "        out_logits, last_state = sess.run(\n",
        "            [modelnn.logits, modelnn.last_state],\n",
        "            feed_dict={\n",
        "                modelnn.X: np.expand_dims(df_train.iloc[upper_b:], axis=0),\n",
        "                modelnn.hidden_layer: init_value,\n",
        "            },\n",
        "        )\n",
        "        output_predict[upper_b + 1: df_train.shape[0] + 1] = out_logits\n",
        "        future_day -= 1\n",
        "        date_ori.append(date_ori[-1] + timedelta(days=1))\n",
        "\n",
        "    init_value = last_state\n",
        "\n",
        "    for i in range(future_day):\n",
        "        o = output_predict[-future_day - timestamp + i:-future_day + i]\n",
        "        out_logits, last_state = sess.run(\n",
        "            [modelnn.logits, modelnn.last_state],\n",
        "            feed_dict={\n",
        "                modelnn.X: np.expand_dims(o, axis=0),\n",
        "                modelnn.hidden_layer: init_value,\n",
        "            },\n",
        "        )\n",
        "        init_value = last_state\n",
        "        output_predict[-future_day + i] = out_logits[-1]\n",
        "        date_ori.append(date_ori[-1] + timedelta(days=1))\n",
        "\n",
        "    output_predict = minmax.inverse_transform(output_predict)\n",
        "    deep_future = anchor(output_predict[:, 0], 0.4)\n",
        "\n",
        "    return deep_future\n",
        "\n",
        "\n",
        "results = []\n",
        "for i in range(simulation_size):\n",
        "    print('simulation %d'%(i + 1))\n",
        "    results.append(forecast())\n",
        "print(results)\n",
        "date_ori = pd.to_datetime(df.iloc[:, 0]).tolist()\n",
        "for i in range(test_size):\n",
        "    date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
        "date_ori = pd.Series(date_ori).dt.strftime(date_format = '%Y-%m-%d').tolist()\n",
        "print(date_ori[-5:])\n",
        "\n",
        "accepted_results = []\n",
        "for r in results:\n",
        "    if (np.array(r[-test_size:]) < np.min(df['Close'])).sum() == 0 and \\\n",
        "    (np.array(r[-test_size:]) > np.max(df['Close']) * 2).sum() == 0:\n",
        "        accepted_results.append(r)\n",
        "print(len(accepted_results))\n",
        "\n",
        "accuracies = [calculate_accuracy(df['Close'].values, r[:-test_size]) for r in accepted_results]\n",
        "\n",
        "plt.figure(figsize = (15, 5))\n",
        "for no, r in enumerate(accepted_results):\n",
        "    plt.plot(r, label = 'forecast %d'%(no + 1))\n",
        "plt.plot(df['Close'], label = 'true trend', c = 'black')\n",
        "plt.legend()\n",
        "plt.title('average accuracy: %.4f'%(np.mean(accuracies)))\n",
        "\n",
        "x_range_future = np.arange(len(results[0]))\n",
        "plt.xticks(x_range_future[::30], date_ori[::30])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "                Open      High       Low     Close  Adj Close     Volume\n",
            "Date                                                                    \n",
            "1995-01-03  1.388393  1.388393  1.352679  1.370536   1.179026   25967200\n",
            "1995-01-04  1.379464  1.415179  1.379464  1.406250   1.209749   39670400\n",
            "1995-01-05  1.401786  1.406250  1.383929  1.388393   1.194387   18410000\n",
            "1995-01-06  1.486607  1.540179  1.468750  1.500000   1.290400  269155600\n",
            "1995-01-09  1.486607  1.495536  1.464286  1.471540   1.265917   68521600\n",
            "          0\n",
            "0  0.002828\n",
            "1  0.002940\n",
            "2  0.002884\n",
            "3  0.003233\n",
            "4  0.003144\n",
            "(6283, 6) (6283, 1)\n",
            "simulation 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b716855cbac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulation_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'simulation %d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0mdate_ori\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-b716855cbac1>\u001b[0m in \u001b[0;36mforecast\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mmodelnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-b716855cbac1>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, learning_rate, num_layers, size, size_layer, output_size, forget_bias)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         rnn_cells = tf.keras.layers.StackedRNNCells(\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mlstm_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_layer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0mstate_is_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         )\n",
            "\u001b[0;32m<ipython-input-4-b716855cbac1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         rnn_cells = tf.keras.layers.StackedRNNCells(\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mlstm_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_layer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0mstate_is_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         )\n",
            "\u001b[0;32m<ipython-input-4-b716855cbac1>\u001b[0m in \u001b[0;36mlstm_cell\u001b[0;34m(size_layer)\u001b[0m\n\u001b[1;32m     76\u001b[0m     ):\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mlstm_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTMCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_is_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         rnn_cells = tf.keras.layers.StackedRNNCells(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, units, activation, recurrent_activation, use_bias, kernel_initializer, recurrent_initializer, bias_initializer, unit_forget_bias, kernel_regularizer, recurrent_regularizer, bias_regularizer, kernel_constraint, recurrent_constraint, bias_constraint, dropout, recurrent_dropout, implementation, **kwargs)\u001b[0m\n\u001b[1;32m   2117\u001b[0m                \u001b[0mimplementation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2118\u001b[0m                **kwargs):\n\u001b[0;32m-> 2119\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTMCell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2120\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_dropout_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_recurrent_dropout_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropoutRNNCellMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_dropout_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m     }\n\u001b[1;32m    299\u001b[0m     \u001b[0;31m# Validate optional keyword arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;31m# Mutable properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mvalidate_kwargs\u001b[0;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'state_is_tuple')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYXRQ_-ltovx"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp4F8xkctIex",
        "outputId": "bbe176fe-e2a0-4c31-f3ff-f9ad9e6456dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "pip install yfinance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting yfinance\n",
            "  Downloading https://files.pythonhosted.org/packages/c2/31/8b374a12b90def92a4e27d0fc595fc43635f395984e36a075244d98bd265/yfinance-0.1.54.tar.gz\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.6/dist-packages (from yfinance) (0.25.3)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.17.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.6/dist-packages (from yfinance) (2.21.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from yfinance) (0.0.9)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2.6.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2019.11.28)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.24->yfinance) (1.12.0)\n",
            "Building wheels for collected packages: yfinance\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.54-py2.py3-none-any.whl size=22411 sha256=4801d20ee2c9af5ea6426250c40e53ceb3adf5b53c38fc30a78297aa24c4f46f\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/e3/5b/ec24dd2984b12d61e0abf26289746c2436a0e7844f26f2515c\n",
            "Successfully built yfinance\n",
            "Installing collected packages: yfinance\n",
            "Successfully installed yfinance-0.1.54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PHxT4jWtpvh",
        "outputId": "2f398d03-391c-40e8-86e2-2f5b1bbc8353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import sys\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import datetime\n",
        "from datetime import timedelta\n",
        "from tqdm import tqdm\n",
        "sns.set()\n",
        "tf.compat.v1.random.set_random_seed(1234)\n",
        "import datetime\n",
        "import sys\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#from datetime import datetime\n",
        "#from datetime import timedelta\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I31F8TNktrLr",
        "outputId": "fdc80645-cbc3-4617-e777-41134dde8eb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter('ignore')\n",
        "sns.set()\n",
        "tf.compat.v1.random.set_random_seed(1234)\n",
        "# To grab stock data\n",
        "import yfinance as fyf\n",
        "from pandas_datareader import data as pdr\n",
        "fyf.pdr_override()\n",
        "stocks = [\"AAPL\"] # If you want to grab multiple stocks add more labels to this list\n",
        "#stocks = [\"AHEALTH\"]\n",
        "# Set start and end dates\n",
        "start = datetime.datetime(2000, 1, 1)\n",
        "end   = datetime.datetime.now()\n",
        "\n",
        "# Grab data\n",
        "#df = pdr.get_data_yahoo(stocks, start = start, end = end)\n",
        "#df = pd.read_csv(\"/content/WTK.csv\")\n",
        "df.index()\n",
        "print(df.tail())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Date  Open  High   Low  Close  Adj Close   Volume\n",
            "2469  11-25-2016  1.03  1.05  1.02   1.05       1.05   854400\n",
            "2470  11-28-2016  1.03  1.04  1.02   1.04       1.04  1223700\n",
            "2471  11-29-2016  1.04  1.04  1.02   1.04       1.04   151300\n",
            "2472  11-30-2016  1.02  1.02  1.01   1.01       1.01   893700\n",
            "2473  12-01-2016  1.01  1.02  1.01   1.02       1.02   386500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CfI5ReFzych",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "97926225-8e6b-40e0-b67b-c3219bcb82c7"
      },
      "source": [
        "df['Date'] = df['Date'].astype('datetime64[ns]')\n",
        "df.info()\n",
        "df = df.sort_values(by=['Date'])\n",
        "\n",
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2474 entries, 765 to 1032\n",
            "Data columns (total 7 columns):\n",
            "Date         2474 non-null datetime64[ns]\n",
            "Open         2474 non-null float64\n",
            "High         2473 non-null float64\n",
            "Low          2474 non-null object\n",
            "Close        2474 non-null float64\n",
            "Adj Close    2474 non-null float64\n",
            "Volume       2474 non-null int64\n",
            "dtypes: datetime64[ns](1), float64(4), int64(1), object(1)\n",
            "memory usage: 154.6+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1007</th>\n",
              "      <td>2020-01-27</td>\n",
              "      <td>0.515</td>\n",
              "      <td>0.515</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.510</td>\n",
              "      <td>0.510</td>\n",
              "      <td>192800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1006</th>\n",
              "      <td>2020-01-28</td>\n",
              "      <td>0.505</td>\n",
              "      <td>0.505</td>\n",
              "      <td>0.485</td>\n",
              "      <td>0.490</td>\n",
              "      <td>0.490</td>\n",
              "      <td>1520300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1005</th>\n",
              "      <td>2020-01-29</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.515</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.510</td>\n",
              "      <td>0.510</td>\n",
              "      <td>456200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004</th>\n",
              "      <td>2020-01-30</td>\n",
              "      <td>0.510</td>\n",
              "      <td>0.510</td>\n",
              "      <td>0.495</td>\n",
              "      <td>0.495</td>\n",
              "      <td>0.495</td>\n",
              "      <td>320900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1032</th>\n",
              "      <td>2020-01-31</td>\n",
              "      <td>0.495</td>\n",
              "      <td>0.495</td>\n",
              "      <td>0.485</td>\n",
              "      <td>0.485</td>\n",
              "      <td>0.485</td>\n",
              "      <td>798200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Date   Open   High    Low  Close  Adj Close   Volume\n",
              "1007 2020-01-27  0.515  0.515   0.51  0.510      0.510   192800\n",
              "1006 2020-01-28  0.505  0.505  0.485  0.490      0.490  1520300\n",
              "1005 2020-01-29  0.500  0.515    0.5  0.510      0.510   456200\n",
              "1004 2020-01-30  0.510  0.510  0.495  0.495      0.495   320900\n",
              "1032 2020-01-31  0.495  0.495  0.485  0.485      0.485   798200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQRnuA4W0y8B"
      },
      "source": [
        "#df = df.set_index('Date')\n",
        "df.to_csv(\"/content/WTK_.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQaBYJs4uVkP",
        "outputId": "144ea2a1-2a4b-4b08-ddf8-52dd53a19ee4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "minmax = MinMaxScaler().fit(df.iloc[:, 4:5].astype('float32')) # Close index\n",
        "df_log = minmax.transform(df.iloc[:, 4:5].astype('float32')) # Close index\n",
        "df_log = pd.DataFrame(df_log)\n",
        "df_log.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.413174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.431138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.437126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.413174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.419162</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0\n",
              "0  0.413174\n",
              "1  0.431138\n",
              "2  0.437126\n",
              "3  0.413174\n",
              "4  0.419162"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_swvPbGue1k",
        "outputId": "66fea68f-1acd-49fb-83bc-f7eaab577bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "simulation_size = 10\n",
        "num_layers = 1\n",
        "size_layer = 128\n",
        "timestamp = 5\n",
        "epoch = 500\n",
        "dropout_rate = 0.8\n",
        "test_size = 7\n",
        "learning_rate = 0.01\n",
        "\n",
        "df_train = df_log\n",
        "df.shape, df_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2474, 6), (2474, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z95enuC8ulXJ"
      },
      "source": [
        "class Model:\n",
        "    def __init__(\n",
        "        self,\n",
        "        learning_rate,\n",
        "        num_layers,\n",
        "        size,\n",
        "        size_layer,\n",
        "        output_size,\n",
        "        forget_bias = 0.1,\n",
        "    ):\n",
        "        def lstm_cell(size_layer):\n",
        "            return tf.nn.rnn_cell.LSTMCell(size_layer, state_is_tuple = False)\n",
        "\n",
        "        rnn_cells = tf.nn.rnn_cell.MultiRNNCell(\n",
        "            [lstm_cell(size_layer) for _ in range(num_layers)],\n",
        "            state_is_tuple = False,\n",
        "        )\n",
        "        self.X = tf.placeholder(tf.float32, (None, None, size))\n",
        "        self.Y = tf.placeholder(tf.float32, (None, output_size))\n",
        "        drop = tf.contrib.rnn.DropoutWrapper(\n",
        "            rnn_cells, output_keep_prob = forget_bias\n",
        "        )\n",
        "        self.hidden_layer = tf.placeholder(\n",
        "            tf.float32, (None, num_layers * 2 * size_layer)\n",
        "        )\n",
        "        self.outputs, self.last_state = tf.nn.dynamic_rnn(\n",
        "            drop, self.X, initial_state = self.hidden_layer, dtype = tf.float32\n",
        "        )\n",
        "        self.logits = tf.layers.dense(self.outputs[-1], output_size)\n",
        "        self.cost = tf.reduce_mean(tf.square(self.Y - self.logits))\n",
        "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(\n",
        "            self.cost\n",
        "        )\n",
        "\n",
        "def calculate_accuracy(real, predict):\n",
        "    real = np.array(real) + 1\n",
        "    predict = np.array(predict) + 1\n",
        "    percentage = 1 - np.sqrt(np.mean(np.square((real - predict) / real)))\n",
        "    return percentage * 100\n",
        "\n",
        "def anchor(signal, weight):\n",
        "    buffer = []\n",
        "    last = signal[0]\n",
        "    for i in signal:\n",
        "        smoothed_val = last * weight + (1 - weight) * i\n",
        "        buffer.append(smoothed_val)\n",
        "        last = smoothed_val\n",
        "    return buffer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrFULa92uqWz"
      },
      "source": [
        "def forecast():\n",
        "    tf.reset_default_graph()\n",
        "    modelnn = Model(\n",
        "        learning_rate, num_layers, df_log.shape[1], size_layer, df_log.shape[1], dropout_rate\n",
        "    )\n",
        "    sess = tf.InteractiveSession()\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    date_ori = pd.to_datetime(df.iloc[:, 0]).tolist()\n",
        "\n",
        "    pbar = tqdm(range(epoch), desc = 'train loop')\n",
        "    for i in pbar:\n",
        "        init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
        "        total_loss, total_acc = [], []\n",
        "        for k in range(0, df_train.shape[0] - 1, timestamp):\n",
        "            index = min(k + timestamp, df_train.shape[0] - 1)\n",
        "            batch_x = np.expand_dims(\n",
        "                df_train.iloc[k : index, :].values, axis = 0\n",
        "            )\n",
        "            batch_y = df_train.iloc[k + 1 : index + 1, :].values\n",
        "            logits, last_state, _, loss = sess.run(\n",
        "                [modelnn.logits, modelnn.last_state, modelnn.optimizer, modelnn.cost],\n",
        "                feed_dict = {\n",
        "                    modelnn.X: batch_x,\n",
        "                    modelnn.Y: batch_y,\n",
        "                    modelnn.hidden_layer: init_value,\n",
        "                },\n",
        "            )\n",
        "            init_value = last_state\n",
        "            total_loss.append(loss)\n",
        "            total_acc.append(calculate_accuracy(batch_y[:, 0], logits[:, 0]))\n",
        "        pbar.set_postfix(cost = np.mean(total_loss), acc = np.mean(total_acc))\n",
        "\n",
        "    future_day = test_size\n",
        "\n",
        "    output_predict = np.zeros((df_train.shape[0] + future_day, df_train.shape[1]))\n",
        "    output_predict[0] = df_train.iloc[0]\n",
        "    upper_b = (df_train.shape[0] // timestamp) * timestamp\n",
        "    init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
        "\n",
        "    for k in range(0, (df_train.shape[0] // timestamp) * timestamp, timestamp):\n",
        "        out_logits, last_state = sess.run(\n",
        "            [modelnn.logits, modelnn.last_state],\n",
        "            feed_dict = {\n",
        "                modelnn.X: np.expand_dims(\n",
        "                    df_train.iloc[k : k + timestamp], axis = 0\n",
        "                ),\n",
        "                modelnn.hidden_layer: init_value,\n",
        "            },\n",
        "        )\n",
        "        init_value = last_state\n",
        "        output_predict[k + 1 : k + timestamp + 1] = out_logits\n",
        "\n",
        "    if upper_b != df_train.shape[0]:\n",
        "        out_logits, last_state = sess.run(\n",
        "            [modelnn.logits, modelnn.last_state],\n",
        "            feed_dict = {\n",
        "                modelnn.X: np.expand_dims(df_train.iloc[upper_b:], axis = 0),\n",
        "                modelnn.hidden_layer: init_value,\n",
        "            },\n",
        "        )\n",
        "        output_predict[upper_b + 1 : df_train.shape[0] + 1] = out_logits\n",
        "        future_day -= 1\n",
        "        date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
        "\n",
        "    init_value = last_state\n",
        "\n",
        "    for i in range(future_day):\n",
        "        o = output_predict[-future_day - timestamp + i:-future_day + i]\n",
        "        out_logits, last_state = sess.run(\n",
        "            [modelnn.logits, modelnn.last_state],\n",
        "            feed_dict = {\n",
        "                modelnn.X: np.expand_dims(o, axis = 0),\n",
        "                modelnn.hidden_layer: init_value,\n",
        "            },\n",
        "        )\n",
        "        init_value = last_state\n",
        "        output_predict[-future_day + i] = out_logits[-1]\n",
        "        date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
        "\n",
        "    output_predict = minmax.inverse_transform(output_predict)\n",
        "    deep_future = anchor(output_predict[:, 0], 0.4)\n",
        "\n",
        "    return deep_future"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m10b9C0buvFE",
        "outputId": "47593472-48ca-44ef-952d-cc959d13f739",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "results = []\n",
        "for i in range(simulation_size):\n",
        "    print('simulation %d'%(i + 1))\n",
        "    results.append(forecast())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "simulation 1\n",
            "WARNING:tensorflow:From <ipython-input-21-d01d21f09afe>:12: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fbe760c35f8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
            "WARNING:tensorflow:From <ipython-input-21-d01d21f09afe>:16: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-21-d01d21f09afe>:27: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From <ipython-input-21-d01d21f09afe>:29: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "train loop: 100%|██████████| 500/500 [18:37<00:00,  2.10s/it, acc=97.8, cost=0.00184]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "simulation 2\n",
            "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fbeb8bb5320>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n",
            "train loop: 100%|██████████| 500/500 [17:53<00:00,  2.15s/it, acc=97.9, cost=0.00149]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "simulation 3\n",
            "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fbe672adbe0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n",
            "train loop: 100%|██████████| 500/500 [17:39<00:00,  2.12s/it, acc=98.2, cost=0.00113]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "simulation 4\n",
            "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fbe672adc88>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n",
            "train loop: 100%|██████████| 500/500 [17:42<00:00,  2.16s/it, acc=97.8, cost=0.00162]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "simulation 5\n",
            "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fbe66883588>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n",
            "train loop: 100%|██████████| 500/500 [17:53<00:00,  2.22s/it, acc=97.8, cost=0.00176]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "simulation 6\n",
            "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fbe644c2898>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n",
            "train loop: 100%|██████████| 500/500 [18:24<00:00,  2.27s/it, acc=98, cost=0.00139]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "simulation 7\n",
            "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fbe632aff28>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n",
            "train loop: 100%|██████████| 500/500 [18:17<00:00,  2.12s/it, acc=97.8, cost=0.00167]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "simulation 8\n",
            "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fbe6214ae48>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n",
            "train loop: 100%|██████████| 500/500 [17:34<00:00,  2.13s/it, acc=97.7, cost=0.00226]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "simulation 9\n",
            "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fbe61082fd0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n",
            "train loop: 100%|██████████| 500/500 [17:46<00:00,  2.13s/it, acc=97.9, cost=0.0014]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "simulation 10\n",
            "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fbe6071ff98>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n",
            "train loop: 100%|██████████| 500/500 [17:45<00:00,  2.17s/it, acc=97.8, cost=0.00165]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1176Gng3h_l",
        "outputId": "2bca36f2-6eff-4e79-cf1b-10833aa49c09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "date_ori = pd.to_datetime(df.iloc[:, 0]).tolist()\n",
        "for i in range(test_size):\n",
        "    date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
        "date_ori = pd.Series(date_ori).dt.strftime(date_format = '%Y-%m-%d').tolist()\n",
        "#date_ori[-5:]\n",
        "date_ori"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " '1970-01-01',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osyYH6wP3njn",
        "outputId": "83695941-5ca7-4045-e376-253196c3de53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accepted_results = []\n",
        "for r in results:\n",
        "    if (np.array(r[-test_size:]) < np.min(df['Close'])).sum() == 0 and \\\n",
        "    (np.array(r[-test_size:]) > np.max(df['Close']) * 2).sum() == 0:\n",
        "        accepted_results.append(r)\n",
        "len(accepted_results)\n",
        "#accepted_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsK2cQP53-wK",
        "outputId": "d03fe6ea-41e0-406c-c01c-e01139e00eb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#for i in accepted_results\n",
        "#df1 = pd.DataFrame(i)\n",
        "#accepted_results[0]\n",
        "#df1 = pd.DataFrame(accepted_results[0])\n",
        "df2 = pd.DataFrame(accepted_results[1])\n",
        "df3 = pd.DataFrame(accepted_results[2])\n",
        "df4 = pd.DataFrame(accepted_results[3])\n",
        "df5 = pd.DataFrame(accepted_results[4])\n",
        "df6 = pd.DataFrame(accepted_results[5])\n",
        "df7 = pd.DataFrame(accepted_results[6])\n",
        "df8 = pd.DataFrame(accepted_results[7])\n",
        "df9 = pd.DataFrame(accepted_results[8])\n",
        "\n",
        "dfAll = pd.concat([df2,df3,df4,df5,df6,df7,df8,df9],axis = 1)\n",
        "dfMean = dfAll.mean(axis = 1, skipna = True)\n",
        "df_col = dfMean.tail(7)\n",
        "df_col.to_csv('/content/sample_data/7days__WTK.csv')\n",
        "#dfAll = df1[0].map(str)+df2[0].map(str)+df3[0].map(str)+df4[0].map(str)\n",
        "\n",
        "#df_col = pd.concat([df.iloc[:, 0:0],df1], axis=1)\n",
        "#df3 = df.iloc[:, 0:0].insert(df1)\n",
        "#df3= pd.concat([df.iloc[:, 0:0], df1], axis=1)\n",
        "\n",
        "#df_col.to_csv('/content/sample_data/test1.csv')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox5Y-3AMP5XD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "531eec34-926a-4463-bbbf-a646dbae57e0"
      },
      "source": [
        "dfAll.tail(10)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2471</th>\n",
              "      <td>0.522226</td>\n",
              "      <td>0.556952</td>\n",
              "      <td>0.500520</td>\n",
              "      <td>0.517970</td>\n",
              "      <td>0.500833</td>\n",
              "      <td>0.549653</td>\n",
              "      <td>0.507244</td>\n",
              "      <td>0.554856</td>\n",
              "      <td>0.472390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2472</th>\n",
              "      <td>0.586633</td>\n",
              "      <td>0.530565</td>\n",
              "      <td>0.504145</td>\n",
              "      <td>0.516599</td>\n",
              "      <td>0.531278</td>\n",
              "      <td>0.572034</td>\n",
              "      <td>0.514699</td>\n",
              "      <td>0.528961</td>\n",
              "      <td>0.467345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2473</th>\n",
              "      <td>0.551822</td>\n",
              "      <td>0.508491</td>\n",
              "      <td>0.496588</td>\n",
              "      <td>0.546839</td>\n",
              "      <td>0.544776</td>\n",
              "      <td>0.578906</td>\n",
              "      <td>0.509856</td>\n",
              "      <td>0.548027</td>\n",
              "      <td>0.502916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2474</th>\n",
              "      <td>0.612670</td>\n",
              "      <td>0.501473</td>\n",
              "      <td>0.507234</td>\n",
              "      <td>0.530068</td>\n",
              "      <td>0.546451</td>\n",
              "      <td>0.558677</td>\n",
              "      <td>0.494513</td>\n",
              "      <td>0.498764</td>\n",
              "      <td>0.464933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2475</th>\n",
              "      <td>0.750057</td>\n",
              "      <td>0.518257</td>\n",
              "      <td>0.559687</td>\n",
              "      <td>0.556092</td>\n",
              "      <td>0.563250</td>\n",
              "      <td>0.588775</td>\n",
              "      <td>0.510843</td>\n",
              "      <td>0.535418</td>\n",
              "      <td>0.468739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2476</th>\n",
              "      <td>0.856165</td>\n",
              "      <td>0.547038</td>\n",
              "      <td>0.561331</td>\n",
              "      <td>0.585506</td>\n",
              "      <td>0.616332</td>\n",
              "      <td>0.622677</td>\n",
              "      <td>0.521069</td>\n",
              "      <td>0.509301</td>\n",
              "      <td>0.432176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2477</th>\n",
              "      <td>0.927503</td>\n",
              "      <td>0.585715</td>\n",
              "      <td>0.524860</td>\n",
              "      <td>0.606218</td>\n",
              "      <td>0.645433</td>\n",
              "      <td>0.616523</td>\n",
              "      <td>0.547208</td>\n",
              "      <td>0.561313</td>\n",
              "      <td>0.509687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2478</th>\n",
              "      <td>0.962525</td>\n",
              "      <td>0.628514</td>\n",
              "      <td>0.531948</td>\n",
              "      <td>0.598464</td>\n",
              "      <td>0.661084</td>\n",
              "      <td>0.610217</td>\n",
              "      <td>0.586318</td>\n",
              "      <td>0.581132</td>\n",
              "      <td>0.475847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2479</th>\n",
              "      <td>0.983011</td>\n",
              "      <td>0.634050</td>\n",
              "      <td>0.513697</td>\n",
              "      <td>0.579510</td>\n",
              "      <td>0.669450</td>\n",
              "      <td>0.639104</td>\n",
              "      <td>0.625818</td>\n",
              "      <td>0.558938</td>\n",
              "      <td>0.557099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2480</th>\n",
              "      <td>0.988880</td>\n",
              "      <td>0.614764</td>\n",
              "      <td>0.486517</td>\n",
              "      <td>0.589270</td>\n",
              "      <td>0.666239</td>\n",
              "      <td>0.653973</td>\n",
              "      <td>0.634729</td>\n",
              "      <td>0.552755</td>\n",
              "      <td>0.579619</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         0         0  ...         0         0         0\n",
              "2471  0.522226  0.556952  0.500520  ...  0.507244  0.554856  0.472390\n",
              "2472  0.586633  0.530565  0.504145  ...  0.514699  0.528961  0.467345\n",
              "2473  0.551822  0.508491  0.496588  ...  0.509856  0.548027  0.502916\n",
              "2474  0.612670  0.501473  0.507234  ...  0.494513  0.498764  0.464933\n",
              "2475  0.750057  0.518257  0.559687  ...  0.510843  0.535418  0.468739\n",
              "2476  0.856165  0.547038  0.561331  ...  0.521069  0.509301  0.432176\n",
              "2477  0.927503  0.585715  0.524860  ...  0.547208  0.561313  0.509687\n",
              "2478  0.962525  0.628514  0.531948  ...  0.586318  0.581132  0.475847\n",
              "2479  0.983011  0.634050  0.513697  ...  0.625818  0.558938  0.557099\n",
              "2480  0.988880  0.614764  0.486517  ...  0.634729  0.552755  0.579619\n",
              "\n",
              "[10 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVddydJAbaQt",
        "outputId": "bc10d625-ada8-47fe-c876-3950d86e4d3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "j\n",
        "#dfAll.tail(30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.120000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.057627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.059366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.061841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.050585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2476</th>\n",
              "      <td>0.432176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2477</th>\n",
              "      <td>0.509687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2478</th>\n",
              "      <td>0.475847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2479</th>\n",
              "      <td>0.557099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2480</th>\n",
              "      <td>0.579619</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2481 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0\n",
              "0     1.120000\n",
              "1     1.057627\n",
              "2     1.059366\n",
              "3     1.061841\n",
              "4     1.050585\n",
              "...        ...\n",
              "2476  0.432176\n",
              "2477  0.509687\n",
              "2478  0.475847\n",
              "2479  0.557099\n",
              "2480  0.579619\n",
              "\n",
              "[2481 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M9QPCvTbxOU",
        "outputId": "f22302e2-93ba-4c18-ca19-402325a4a1f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvmmZEkQ4PEO",
        "outputId": "9a9e7e07-1227-4960-d3d5-145707d98791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        }
      },
      "source": [
        "accuracies = [calculate_accuracy(df['Close'].values, r[:-test_size]) for r in accepted_results]\n",
        "\n",
        "plt.figure(figsize = (15, 5))\n",
        "for no, r in enumerate(accepted_results):\n",
        "    plt.plot(r, label = 'forecast %d'%(no + 1))\n",
        "plt.plot(df['Close'], label = 'true trend', c = 'black')\n",
        "plt.legend()\n",
        "plt.title('average accuracy: %.4f'%(np.mean(accuracies)))\n",
        "\n",
        "x_range_future = np.arange(len(results[0]))\n",
        "plt.xticks(x_range_future[::30], date_ori[::30])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/plotting/_matplotlib/converter.py:103: FutureWarning: Using an implicitly registered datetime converter for a matplotlib plotting method. The converter was registered by pandas on import. Future versions of pandas will require you to explicitly register matplotlib converters.\n",
            "\n",
            "To register the converters:\n",
            "\t>>> from pandas.plotting import register_matplotlib_converters\n",
            "\t>>> register_matplotlib_converters()\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-4915baf6d393>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mx_range_future\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_range_future\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_ori\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'date_ori' is not defined"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2061\u001b[0m                         \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m                         \u001b[0mdryrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   2064\u001b[0m                     \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cachedRenderer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mRendererAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1707\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1709\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2605\u001b[0m                 \u001b[0martists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2607\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_title_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2609\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxison\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minframe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_title_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2547\u001b[0m                     if (ax.xaxis.get_label_position() == 'top' or\n\u001b[1;32m   2548\u001b[0m                             ax.xaxis.get_ticks_position() in choices):\n\u001b[0;32m-> 2549\u001b[0;31m                         \u001b[0mbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2550\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2551\u001b[0m                         \u001b[0mbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_window_extent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_label_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mticks\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdrawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \"\"\"\n\u001b[0;32m-> 1079\u001b[0;31m         \u001b[0mmajor_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m         \u001b[0mmajor_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m         \u001b[0mmajor_ticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_major_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_majorticklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0;34m\"\"\"Get the array of major tick locations in data coordinates.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_minorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/dates.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m         \u001b[0;34m'Return the locations of the ticks'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1428\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1429\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/dates.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0;34m'Refresh internal information based on current limits.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mdmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewlim_to_dt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_locator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/dates.py\u001b[0m in \u001b[0;36mviewlim_to_dt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1197\u001b[0m                              \u001b[0;34m'often happens if you pass a non-datetime '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m                              \u001b[0;34m'value to an axis that has datetime units'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m                              .format(vmin))\n\u001b[0m\u001b[1;32m   1200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnum2date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum2date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: view limit minimum -36872.700000000004 is less than 1 and is an invalid Matplotlib date value. This often happens if you pass a non-datetime value to an axis that has datetime units"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNLkKphn6zsh",
        "outputId": "9c27b5e9-8e06-435c-b102-0c08d1efa19f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        }
      },
      "source": [
        "import yfinance as yf\n",
        "\n",
        "msft = yf.Ticker(\"MSFT\")\n",
        "hist = msft.history(period=\"max\")\n",
        "hist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Dividends</th>\n",
              "      <th>Stock Splits</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1986-03-13</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1031788800</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1986-03-14</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>308160000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1986-03-17</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.07</td>\n",
              "      <td>133171200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1986-03-18</th>\n",
              "      <td>0.07</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>67766400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1986-03-19</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>47894400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-27</th>\n",
              "      <td>161.15</td>\n",
              "      <td>163.38</td>\n",
              "      <td>160.20</td>\n",
              "      <td>162.28</td>\n",
              "      <td>32078100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-28</th>\n",
              "      <td>163.78</td>\n",
              "      <td>165.76</td>\n",
              "      <td>163.07</td>\n",
              "      <td>165.46</td>\n",
              "      <td>24899900</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-29</th>\n",
              "      <td>167.84</td>\n",
              "      <td>168.75</td>\n",
              "      <td>165.69</td>\n",
              "      <td>168.04</td>\n",
              "      <td>34754500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-30</th>\n",
              "      <td>174.05</td>\n",
              "      <td>174.05</td>\n",
              "      <td>170.79</td>\n",
              "      <td>172.78</td>\n",
              "      <td>51597500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-31</th>\n",
              "      <td>172.21</td>\n",
              "      <td>172.40</td>\n",
              "      <td>169.58</td>\n",
              "      <td>170.23</td>\n",
              "      <td>36113300</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8542 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              Open    High     Low   Close      Volume  Dividends  Stock Splits\n",
              "Date                                                                           \n",
              "1986-03-13    0.06    0.07    0.06    0.06  1031788800        0.0           0.0\n",
              "1986-03-14    0.06    0.07    0.06    0.06   308160000        0.0           0.0\n",
              "1986-03-17    0.06    0.07    0.06    0.07   133171200        0.0           0.0\n",
              "1986-03-18    0.07    0.07    0.06    0.06    67766400        0.0           0.0\n",
              "1986-03-19    0.06    0.06    0.06    0.06    47894400        0.0           0.0\n",
              "...            ...     ...     ...     ...         ...        ...           ...\n",
              "2020-01-27  161.15  163.38  160.20  162.28    32078100        0.0           0.0\n",
              "2020-01-28  163.78  165.76  163.07  165.46    24899900        0.0           0.0\n",
              "2020-01-29  167.84  168.75  165.69  168.04    34754500        0.0           0.0\n",
              "2020-01-30  174.05  174.05  170.79  172.78    51597500        0.0           0.0\n",
              "2020-01-31  172.21  172.40  169.58  170.23    36113300        0.0           0.0\n",
              "\n",
              "[8542 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    }
  ]
}